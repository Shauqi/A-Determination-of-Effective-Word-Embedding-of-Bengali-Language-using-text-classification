{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FastText + CNN + LSTM.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"FZvP_g-SV47j","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":88},"outputId":"0f58a834-4c02-4235-d76e-7ddc2c3ca43a","executionInfo":{"status":"ok","timestamp":1560102355121,"user_tz":-360,"elapsed":18902,"user":{"displayName":"Mahmudul Hasan","photoUrl":"","userId":"10838423032874605851"}}},"source":["from google.colab import drive\n","import numpy as np\n","import pandas as pd\n","drive.mount('/content/gdrive')\n","bengali_news_after_preprocessing = pd.read_pickle('/content/gdrive/My Drive/Projects/Bengali Text Classification/Bengali_Text_after_preprocessing.pkl')\n","from sklearn.externals import joblib\n","filename = '/content/gdrive/My Drive/Projects/Bengali Text Classification/fastText_Bangla_content_full.sav'\n","loaded_model = joblib.load(filename)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n","  warnings.warn(msg, category=DeprecationWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Bh152mlTWClV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"b7e1e254-481c-406f-d652-37e7336cd92f","executionInfo":{"status":"ok","timestamp":1560102361293,"user_tz":-360,"elapsed":2148,"user":{"displayName":"Mahmudul Hasan","photoUrl":"","userId":"10838423032874605851"}}},"source":["import keras.backend as K\n","import numpy as np\n","number_of_sample, max_number_of_words, word_vector_size = 40000, 50, 32\n","temp = bengali_news_after_preprocessing.loc[:number_of_sample-1,:max_number_of_words-1]"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"BL1dPKt5WNAp","colab_type":"code","colab":{}},"source":["temp = temp.replace(['ঘস', 'ফগ', 'ঝবঃ', 'ঋন', 'ঊঘ', '\\u09e4', 'ওৎ', 'গথ', 'খঢ', 'ঝ’', ' ং', 'ঔ', 'ডড', 'গঘ'], None)\n","X = np.zeros((number_of_sample, max_number_of_words, word_vector_size), dtype=K.floatx())\n","for i in temp.index:\n","  X[i,:,:] = loaded_model.wv[temp.loc[i,:]]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kx4gwqnUWO8R","colab_type":"code","colab":{}},"source":["bengali_news = pd.read_pickle('/content/gdrive/My Drive/Projects/Bengali Text Classification/40k_bangla_newspaper_article.p')\n","bengali_news_dataframe = pd.DataFrame(bengali_news)\n","y = bengali_news_dataframe['category']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pDj7CROuWRrp","colab_type":"code","colab":{}},"source":["from sklearn import preprocessing\n","import keras\n","import numpy as np\n","le = preprocessing.LabelEncoder()\n","le.fit(y)\n","enc = le.transform(y)\n","y = keras.utils.to_categorical(enc)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ltHADvLlWVsg","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","X_train, X_val, y_train, y_val = train_test_split(X, y, shuffle = True, test_size=0.125)\n","X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, shuffle = True, test_size=0.20)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"g2Z737RiWYM4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":139},"outputId":"6aa1fd94-3fd8-49dd-bd83-79873262c59f","executionInfo":{"status":"ok","timestamp":1560102427969,"user_tz":-360,"elapsed":1517,"user":{"displayName":"Mahmudul Hasan","photoUrl":"","userId":"10838423032874605851"}}},"source":["from keras.models import Sequential\n","from keras.layers import Conv1D, Dropout, Dense, Flatten, LSTM, MaxPooling1D, Bidirectional\n","from keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping, TensorBoard\n","\n","\n","model = Sequential()\n","\n","model.add(Conv1D(32, kernel_size=3, activation='elu', padding='same',\n","                 input_shape=(max_number_of_words, word_vector_size)))\n","model.add(Conv1D(32, kernel_size=3, activation='elu', padding='same'))\n","model.add(Conv1D(32, kernel_size=3, activation='relu', padding='same'))\n","model.add(MaxPooling1D(pool_size=3))\n","\n","model.add(Bidirectional(LSTM(256, dropout=0.2, recurrent_dropout=0.3)))\n","\n","model.add(Dense(256, activation='sigmoid'))\n","model.add(Dropout(0.2))\n","model.add(Dense(256, activation='sigmoid'))\n","model.add(Dropout(0.25))\n","model.add(Dense(256, activation='sigmoid'))\n","model.add(Dropout(0.25))\n","\n","model.add(Dense(13, activation='softmax'))\n","\n","model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001, decay=1e-6), metrics=['accuracy'])"],"execution_count":7,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9JD8UfRZWdcI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":544},"outputId":"e7e29e86-4f55-4593-f009-ebdfcf905550","executionInfo":{"status":"ok","timestamp":1560102471894,"user_tz":-360,"elapsed":758,"user":{"displayName":"Mahmudul Hasan","photoUrl":"","userId":"10838423032874605851"}}},"source":["model.summary()"],"execution_count":8,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv1d_1 (Conv1D)            (None, 50, 32)            3104      \n","_________________________________________________________________\n","conv1d_2 (Conv1D)            (None, 50, 32)            3104      \n","_________________________________________________________________\n","conv1d_3 (Conv1D)            (None, 50, 32)            3104      \n","_________________________________________________________________\n","max_pooling1d_1 (MaxPooling1 (None, 16, 32)            0         \n","_________________________________________________________________\n","bidirectional_1 (Bidirection (None, 512)               591872    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 256)               131328    \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 256)               65792     \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 256)               65792     \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 13)                3341      \n","=================================================================\n","Total params: 867,437\n","Trainable params: 867,437\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bkrt1heEWoWg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":3505},"outputId":"4d6ca7f1-5063-43a2-c145-26c8116963d9","executionInfo":{"status":"ok","timestamp":1560103011710,"user_tz":-360,"elapsed":530250,"user":{"displayName":"Mahmudul Hasan","photoUrl":"","userId":"10838423032874605851"}}},"source":["history = model.fit(X_train, y_train, batch_size= 500, shuffle=True, epochs= 100, validation_data=(X_val, y_val))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Train on 35000 samples, validate on 4000 samples\n","Epoch 1/100\n","35000/35000 [==============================] - 10s 298us/step - loss: 2.2375 - acc: 0.2447 - val_loss: 1.9061 - val_acc: 0.3065\n","Epoch 2/100\n","35000/35000 [==============================] - 5s 148us/step - loss: 1.9556 - acc: 0.3294 - val_loss: 1.7554 - val_acc: 0.4763\n","Epoch 3/100\n","35000/35000 [==============================] - 5s 155us/step - loss: 1.7763 - acc: 0.4440 - val_loss: 1.5907 - val_acc: 0.4902\n","Epoch 4/100\n","35000/35000 [==============================] - 5s 151us/step - loss: 1.6414 - acc: 0.4709 - val_loss: 1.4519 - val_acc: 0.4968\n","Epoch 5/100\n","35000/35000 [==============================] - 5s 152us/step - loss: 1.5191 - acc: 0.5173 - val_loss: 1.3308 - val_acc: 0.5667\n","Epoch 6/100\n","35000/35000 [==============================] - 5s 151us/step - loss: 1.4074 - acc: 0.5585 - val_loss: 1.2216 - val_acc: 0.6370\n","Epoch 7/100\n","35000/35000 [==============================] - 5s 151us/step - loss: 1.3050 - acc: 0.5993 - val_loss: 1.1229 - val_acc: 0.6528\n","Epoch 8/100\n","35000/35000 [==============================] - 5s 149us/step - loss: 1.2218 - acc: 0.6258 - val_loss: 1.0623 - val_acc: 0.6673\n","Epoch 9/100\n","35000/35000 [==============================] - 5s 150us/step - loss: 1.1610 - acc: 0.6421 - val_loss: 1.0217 - val_acc: 0.6800\n","Epoch 10/100\n","35000/35000 [==============================] - 5s 152us/step - loss: 1.1176 - acc: 0.6574 - val_loss: 0.9916 - val_acc: 0.6930\n","Epoch 11/100\n","35000/35000 [==============================] - 5s 150us/step - loss: 1.0831 - acc: 0.6650 - val_loss: 0.9661 - val_acc: 0.7020\n","Epoch 12/100\n","35000/35000 [==============================] - 5s 151us/step - loss: 1.0547 - acc: 0.6719 - val_loss: 0.9446 - val_acc: 0.7045\n","Epoch 13/100\n","35000/35000 [==============================] - 5s 151us/step - loss: 1.0367 - acc: 0.6760 - val_loss: 0.9291 - val_acc: 0.7037\n","Epoch 14/100\n","35000/35000 [==============================] - 5s 152us/step - loss: 1.0126 - acc: 0.6831 - val_loss: 0.9073 - val_acc: 0.7135\n","Epoch 15/100\n","35000/35000 [==============================] - 5s 150us/step - loss: 0.9952 - acc: 0.6913 - val_loss: 0.8903 - val_acc: 0.7225\n","Epoch 16/100\n","35000/35000 [==============================] - 5s 152us/step - loss: 0.9801 - acc: 0.6923 - val_loss: 0.8831 - val_acc: 0.7185\n","Epoch 17/100\n","35000/35000 [==============================] - 5s 150us/step - loss: 0.9645 - acc: 0.7021 - val_loss: 0.8655 - val_acc: 0.7360\n","Epoch 18/100\n","35000/35000 [==============================] - 5s 148us/step - loss: 0.9443 - acc: 0.7073 - val_loss: 0.8521 - val_acc: 0.7375\n","Epoch 19/100\n","35000/35000 [==============================] - 5s 149us/step - loss: 0.9265 - acc: 0.7148 - val_loss: 0.8388 - val_acc: 0.7420\n","Epoch 20/100\n","35000/35000 [==============================] - 5s 149us/step - loss: 0.9129 - acc: 0.7181 - val_loss: 0.8299 - val_acc: 0.7448\n","Epoch 21/100\n","35000/35000 [==============================] - 5s 149us/step - loss: 0.9015 - acc: 0.7236 - val_loss: 0.8257 - val_acc: 0.7417\n","Epoch 22/100\n","35000/35000 [==============================] - 5s 152us/step - loss: 0.8851 - acc: 0.7269 - val_loss: 0.8091 - val_acc: 0.7533\n","Epoch 23/100\n","35000/35000 [==============================] - 5s 150us/step - loss: 0.8749 - acc: 0.7297 - val_loss: 0.8043 - val_acc: 0.7513\n","Epoch 24/100\n","35000/35000 [==============================] - 5s 153us/step - loss: 0.8631 - acc: 0.7329 - val_loss: 0.7964 - val_acc: 0.7562\n","Epoch 25/100\n","35000/35000 [==============================] - 5s 148us/step - loss: 0.8475 - acc: 0.7362 - val_loss: 0.7850 - val_acc: 0.7585\n","Epoch 26/100\n","35000/35000 [==============================] - 5s 149us/step - loss: 0.8410 - acc: 0.7393 - val_loss: 0.7751 - val_acc: 0.7638\n","Epoch 27/100\n","35000/35000 [==============================] - 5s 151us/step - loss: 0.8306 - acc: 0.7413 - val_loss: 0.7672 - val_acc: 0.7665\n","Epoch 28/100\n","35000/35000 [==============================] - 5s 150us/step - loss: 0.8223 - acc: 0.7461 - val_loss: 0.7608 - val_acc: 0.7665\n","Epoch 29/100\n","35000/35000 [==============================] - 5s 150us/step - loss: 0.8140 - acc: 0.7463 - val_loss: 0.7584 - val_acc: 0.7712\n","Epoch 30/100\n","35000/35000 [==============================] - 5s 146us/step - loss: 0.7990 - acc: 0.7517 - val_loss: 0.7518 - val_acc: 0.7693\n","Epoch 31/100\n","35000/35000 [==============================] - 5s 149us/step - loss: 0.7994 - acc: 0.7507 - val_loss: 0.7567 - val_acc: 0.7610\n","Epoch 32/100\n","35000/35000 [==============================] - 5s 150us/step - loss: 0.7891 - acc: 0.7545 - val_loss: 0.7473 - val_acc: 0.7690\n","Epoch 33/100\n","35000/35000 [==============================] - 5s 149us/step - loss: 0.7854 - acc: 0.7530 - val_loss: 0.7365 - val_acc: 0.7750\n","Epoch 34/100\n","35000/35000 [==============================] - 5s 150us/step - loss: 0.7744 - acc: 0.7594 - val_loss: 0.7276 - val_acc: 0.7767\n","Epoch 35/100\n","35000/35000 [==============================] - 5s 146us/step - loss: 0.7710 - acc: 0.7587 - val_loss: 0.7299 - val_acc: 0.7755\n","Epoch 36/100\n","35000/35000 [==============================] - 5s 150us/step - loss: 0.7650 - acc: 0.7599 - val_loss: 0.7231 - val_acc: 0.7780\n","Epoch 37/100\n","35000/35000 [==============================] - 5s 151us/step - loss: 0.7563 - acc: 0.7637 - val_loss: 0.7233 - val_acc: 0.7762\n","Epoch 38/100\n","35000/35000 [==============================] - 5s 147us/step - loss: 0.7489 - acc: 0.7657 - val_loss: 0.7163 - val_acc: 0.7765\n","Epoch 39/100\n","35000/35000 [==============================] - 5s 150us/step - loss: 0.7405 - acc: 0.7677 - val_loss: 0.7113 - val_acc: 0.7732\n","Epoch 40/100\n","35000/35000 [==============================] - 5s 150us/step - loss: 0.7405 - acc: 0.7689 - val_loss: 0.7049 - val_acc: 0.7790\n","Epoch 41/100\n","35000/35000 [==============================] - 5s 150us/step - loss: 0.7341 - acc: 0.7701 - val_loss: 0.6999 - val_acc: 0.7802\n","Epoch 42/100\n","35000/35000 [==============================] - 5s 151us/step - loss: 0.7281 - acc: 0.7685 - val_loss: 0.6984 - val_acc: 0.7820\n","Epoch 43/100\n","35000/35000 [==============================] - 5s 150us/step - loss: 0.7193 - acc: 0.7728 - val_loss: 0.7001 - val_acc: 0.7777\n","Epoch 44/100\n","35000/35000 [==============================] - 5s 149us/step - loss: 0.7175 - acc: 0.7732 - val_loss: 0.6857 - val_acc: 0.7840\n","Epoch 45/100\n","35000/35000 [==============================] - 5s 148us/step - loss: 0.7151 - acc: 0.7748 - val_loss: 0.6878 - val_acc: 0.7845\n","Epoch 46/100\n","35000/35000 [==============================] - 5s 151us/step - loss: 0.7082 - acc: 0.7755 - val_loss: 0.6826 - val_acc: 0.7882\n","Epoch 47/100\n","35000/35000 [==============================] - 5s 148us/step - loss: 0.7011 - acc: 0.7780 - val_loss: 0.6805 - val_acc: 0.7873\n","Epoch 48/100\n","35000/35000 [==============================] - 5s 150us/step - loss: 0.6971 - acc: 0.7820 - val_loss: 0.6837 - val_acc: 0.7880\n","Epoch 49/100\n","35000/35000 [==============================] - 5s 148us/step - loss: 0.6924 - acc: 0.7821 - val_loss: 0.6752 - val_acc: 0.7877\n","Epoch 50/100\n","35000/35000 [==============================] - 5s 149us/step - loss: 0.6890 - acc: 0.7823 - val_loss: 0.6730 - val_acc: 0.7902\n","Epoch 51/100\n","35000/35000 [==============================] - 5s 149us/step - loss: 0.6877 - acc: 0.7831 - val_loss: 0.6677 - val_acc: 0.7915\n","Epoch 52/100\n","35000/35000 [==============================] - 5s 145us/step - loss: 0.6792 - acc: 0.7865 - val_loss: 0.6653 - val_acc: 0.7940\n","Epoch 53/100\n","35000/35000 [==============================] - 5s 150us/step - loss: 0.6751 - acc: 0.7861 - val_loss: 0.6686 - val_acc: 0.7905\n","Epoch 54/100\n","35000/35000 [==============================] - 5s 145us/step - loss: 0.6754 - acc: 0.7863 - val_loss: 0.6638 - val_acc: 0.7925\n","Epoch 55/100\n","35000/35000 [==============================] - 5s 146us/step - loss: 0.6668 - acc: 0.7896 - val_loss: 0.6588 - val_acc: 0.7938\n","Epoch 56/100\n","35000/35000 [==============================] - 5s 148us/step - loss: 0.6651 - acc: 0.7901 - val_loss: 0.6517 - val_acc: 0.7935\n","Epoch 57/100\n","35000/35000 [==============================] - 5s 150us/step - loss: 0.6611 - acc: 0.7912 - val_loss: 0.6515 - val_acc: 0.7953\n","Epoch 58/100\n","35000/35000 [==============================] - 5s 151us/step - loss: 0.6577 - acc: 0.7951 - val_loss: 0.6500 - val_acc: 0.7953\n","Epoch 59/100\n","35000/35000 [==============================] - 5s 151us/step - loss: 0.6570 - acc: 0.7937 - val_loss: 0.6462 - val_acc: 0.7973\n","Epoch 60/100\n","35000/35000 [==============================] - 5s 150us/step - loss: 0.6533 - acc: 0.7957 - val_loss: 0.6480 - val_acc: 0.7977\n","Epoch 61/100\n","35000/35000 [==============================] - 5s 151us/step - loss: 0.6505 - acc: 0.7966 - val_loss: 0.6464 - val_acc: 0.7975\n","Epoch 62/100\n","35000/35000 [==============================] - 5s 149us/step - loss: 0.6458 - acc: 0.7973 - val_loss: 0.6411 - val_acc: 0.7968\n","Epoch 63/100\n","35000/35000 [==============================] - 5s 148us/step - loss: 0.6449 - acc: 0.7970 - val_loss: 0.6381 - val_acc: 0.7983\n","Epoch 64/100\n","35000/35000 [==============================] - 5s 146us/step - loss: 0.6418 - acc: 0.7959 - val_loss: 0.6426 - val_acc: 0.8030\n","Epoch 65/100\n","35000/35000 [==============================] - 5s 149us/step - loss: 0.6385 - acc: 0.7993 - val_loss: 0.6399 - val_acc: 0.8003\n","Epoch 66/100\n","35000/35000 [==============================] - 5s 147us/step - loss: 0.6341 - acc: 0.8003 - val_loss: 0.6349 - val_acc: 0.8027\n","Epoch 67/100\n","35000/35000 [==============================] - 5s 149us/step - loss: 0.6321 - acc: 0.8016 - val_loss: 0.6366 - val_acc: 0.8020\n","Epoch 68/100\n","35000/35000 [==============================] - 5s 145us/step - loss: 0.6253 - acc: 0.8037 - val_loss: 0.6313 - val_acc: 0.8045\n","Epoch 69/100\n","35000/35000 [==============================] - 5s 149us/step - loss: 0.6254 - acc: 0.8039 - val_loss: 0.6356 - val_acc: 0.8062\n","Epoch 70/100\n","35000/35000 [==============================] - 5s 149us/step - loss: 0.6222 - acc: 0.8042 - val_loss: 0.6268 - val_acc: 0.8040\n","Epoch 71/100\n","35000/35000 [==============================] - 5s 148us/step - loss: 0.6191 - acc: 0.8036 - val_loss: 0.6265 - val_acc: 0.8045\n","Epoch 72/100\n","35000/35000 [==============================] - 5s 148us/step - loss: 0.6164 - acc: 0.8070 - val_loss: 0.6249 - val_acc: 0.8032\n","Epoch 73/100\n","35000/35000 [==============================] - 5s 149us/step - loss: 0.6153 - acc: 0.8061 - val_loss: 0.6269 - val_acc: 0.8043\n","Epoch 74/100\n","35000/35000 [==============================] - 5s 148us/step - loss: 0.6140 - acc: 0.8079 - val_loss: 0.6247 - val_acc: 0.8038\n","Epoch 75/100\n","35000/35000 [==============================] - 5s 147us/step - loss: 0.6114 - acc: 0.8087 - val_loss: 0.6229 - val_acc: 0.8053\n","Epoch 76/100\n","35000/35000 [==============================] - 5s 148us/step - loss: 0.6072 - acc: 0.8090 - val_loss: 0.6213 - val_acc: 0.8110\n","Epoch 77/100\n","35000/35000 [==============================] - 5s 148us/step - loss: 0.6048 - acc: 0.8091 - val_loss: 0.6226 - val_acc: 0.8067\n","Epoch 78/100\n","35000/35000 [==============================] - 5s 148us/step - loss: 0.6039 - acc: 0.8093 - val_loss: 0.6182 - val_acc: 0.8080\n","Epoch 79/100\n","35000/35000 [==============================] - 5s 146us/step - loss: 0.5990 - acc: 0.8107 - val_loss: 0.6185 - val_acc: 0.8077\n","Epoch 80/100\n","35000/35000 [==============================] - 5s 148us/step - loss: 0.5984 - acc: 0.8111 - val_loss: 0.6158 - val_acc: 0.8082\n","Epoch 81/100\n","35000/35000 [==============================] - 5s 145us/step - loss: 0.5945 - acc: 0.8117 - val_loss: 0.6166 - val_acc: 0.8125\n","Epoch 82/100\n","35000/35000 [==============================] - 5s 150us/step - loss: 0.5912 - acc: 0.8128 - val_loss: 0.6226 - val_acc: 0.8085\n","Epoch 83/100\n","35000/35000 [==============================] - 5s 146us/step - loss: 0.5886 - acc: 0.8149 - val_loss: 0.6168 - val_acc: 0.8117\n","Epoch 84/100\n","35000/35000 [==============================] - 5s 151us/step - loss: 0.5903 - acc: 0.8140 - val_loss: 0.6115 - val_acc: 0.8098\n","Epoch 85/100\n","35000/35000 [==============================] - 5s 148us/step - loss: 0.5869 - acc: 0.8163 - val_loss: 0.6108 - val_acc: 0.8108\n","Epoch 86/100\n","35000/35000 [==============================] - 5s 148us/step - loss: 0.5843 - acc: 0.8151 - val_loss: 0.6163 - val_acc: 0.8105\n","Epoch 87/100\n","35000/35000 [==============================] - 5s 150us/step - loss: 0.5848 - acc: 0.8164 - val_loss: 0.6123 - val_acc: 0.8100\n","Epoch 88/100\n","35000/35000 [==============================] - 5s 150us/step - loss: 0.5800 - acc: 0.8161 - val_loss: 0.6060 - val_acc: 0.8128\n","Epoch 89/100\n","35000/35000 [==============================] - 5s 148us/step - loss: 0.5759 - acc: 0.8173 - val_loss: 0.6068 - val_acc: 0.8125\n","Epoch 90/100\n","35000/35000 [==============================] - 5s 148us/step - loss: 0.5765 - acc: 0.8176 - val_loss: 0.6062 - val_acc: 0.8130\n","Epoch 91/100\n","35000/35000 [==============================] - 5s 148us/step - loss: 0.5730 - acc: 0.8188 - val_loss: 0.6052 - val_acc: 0.8118\n","Epoch 92/100\n","35000/35000 [==============================] - 5s 150us/step - loss: 0.5719 - acc: 0.8200 - val_loss: 0.6109 - val_acc: 0.8090\n","Epoch 93/100\n","35000/35000 [==============================] - 5s 146us/step - loss: 0.5696 - acc: 0.8193 - val_loss: 0.6024 - val_acc: 0.8120\n","Epoch 94/100\n","35000/35000 [==============================] - 5s 147us/step - loss: 0.5696 - acc: 0.8203 - val_loss: 0.6015 - val_acc: 0.8140\n","Epoch 95/100\n","35000/35000 [==============================] - 5s 148us/step - loss: 0.5658 - acc: 0.8202 - val_loss: 0.5984 - val_acc: 0.8118\n","Epoch 96/100\n","35000/35000 [==============================] - 5s 147us/step - loss: 0.5674 - acc: 0.8205 - val_loss: 0.6007 - val_acc: 0.8120\n","Epoch 97/100\n","35000/35000 [==============================] - 5s 149us/step - loss: 0.5619 - acc: 0.8211 - val_loss: 0.5983 - val_acc: 0.8128\n","Epoch 98/100\n","35000/35000 [==============================] - 5s 148us/step - loss: 0.5620 - acc: 0.8211 - val_loss: 0.5994 - val_acc: 0.8135\n","Epoch 99/100\n","35000/35000 [==============================] - 5s 149us/step - loss: 0.5593 - acc: 0.8248 - val_loss: 0.5997 - val_acc: 0.8125\n","Epoch 100/100\n","35000/35000 [==============================] - 5s 149us/step - loss: 0.5557 - acc: 0.8257 - val_loss: 0.6093 - val_acc: 0.8157\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BeaGmZ4wWq3w","colab_type":"code","colab":{}},"source":["predicts = model.predict(X_test)\n","import numpy as np\n","def decode(le, one_hot):\n","    dec = np.argmax(one_hot, axis=1)\n","    return le.inverse_transform(dec)\n","y_test = decode(le, y_test)\n","y_preds = decode(le, predicts)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MfRZa1gYWvf8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":615},"outputId":"ec5d50ec-b566-4ed7-c2a3-284eee9607e7","executionInfo":{"status":"ok","timestamp":1560103117127,"user_tz":-360,"elapsed":800,"user":{"displayName":"Mahmudul Hasan","photoUrl":"","userId":"10838423032874605851"}}},"source":["from sklearn import metrics\n","\n","print(metrics.accuracy_score(y_test, y_preds))\n","\n","print(metrics.confusion_matrix(y_test, y_preds))\n","\n","print(metrics.classification_report(y_test, y_preds))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["0.815\n","[[  0   1   0   0   0   0   0   0   0   7   0   0]\n"," [  0 265   0   5   1   3   9   1   0  22   1   1]\n"," [  0   3   0   0   0   2   0   0   0   2   0   0]\n"," [  0  11   0  90   1   0   0   0   0  12   0   3]\n"," [  0   9   0   0  13   0   0   1   0   3   0   3]\n"," [  0   3   0   0   0  52   1   0   0   1   0   2]\n"," [  0   3   0   1   0   3  22   0   0   7   1   1]\n"," [  0   0   0   0   0   1   0  22   0   3   1   2]\n"," [  0   1   0   0   0   0   1   0   0   2   0   1]\n"," [  0  18   0   5   0   1   3   2   0 236   2   3]\n"," [  0   1   0   0   0   1   1   0   0   0  71   0]\n"," [  0   1   0   6   0   0   1   0   0   4   0  44]]\n","                    precision    recall  f1-score   support\n","\n","art-and-literature       0.00      0.00      0.00         8\n","        bangladesh       0.84      0.86      0.85       308\n","       durporobash       0.00      0.00      0.00         7\n","           economy       0.84      0.77      0.80       117\n","         education       0.87      0.45      0.59        29\n","     entertainment       0.83      0.88      0.85        59\n","     international       0.58      0.58      0.58        38\n","        life-style       0.85      0.76      0.80        29\n","      northamerica       0.00      0.00      0.00         5\n","           opinion       0.79      0.87      0.83       270\n","            sports       0.93      0.96      0.95        74\n","        technology       0.73      0.79      0.76        56\n","\n","          accuracy                           0.81      1000\n","         macro avg       0.60      0.58      0.58      1000\n","      weighted avg       0.80      0.81      0.80      1000\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n","  'precision', 'predicted', average, warn_for)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ahSRhD2YWyE8","colab_type":"code","colab":{}},"source":["accuracy, val_accuracy = np.array(history.history[\"acc\"]), np.array(history.history[\"val_acc\"])\n","accuracy, val_accuracy = accuracy.reshape(100,1), val_accuracy.reshape(100,1)\n","accuracies = np.concatenate((accuracy,val_accuracy),axis=1)\n","np.savetxt('/content/gdrive/My Drive/Projects/Bengali Text Classification/temp.csv',accuracies,delimiter=\",\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rVU2P_fwZH0W","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}