{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FastText + CNN.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"CgOelJ11JvRF","colab_type":"text"},"source":["### Converting preprocessed text into vectors using fasttext embedding."]},{"cell_type":"code","metadata":{"id":"SXe8uEAgIRjR","colab_type":"code","outputId":"726fdb09-d74d-48c4-c28f-6a6da6a84a8b","executionInfo":{"status":"ok","timestamp":1560452514288,"user_tz":-360,"elapsed":27829,"user":{"displayName":"Pritom Mojumder","photoUrl":"https://lh5.googleusercontent.com/-f2ateZ-M7oE/AAAAAAAAAAI/AAAAAAAAAO0/QSPkIPgKOx4/s64/photo.jpg","userId":"01710067307887133491"}},"colab":{"base_uri":"https://localhost:8080/","height":90}},"source":["from google.colab import drive\n","import numpy as np\n","import pandas as pd\n","drive.mount('/content/gdrive')\n","bengali_news_after_preprocessing = pd.read_pickle('/content/gdrive/My Drive/Projects/Bengali Text Classification/Bengali_Text_after_preprocessing.pkl')\n","from sklearn.externals import joblib\n","filename = '/content/gdrive/My Drive/Projects/Bengali Text Classification/fastText_Bangla_content_full.sav'\n","loaded_model = joblib.load(filename)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n","  warnings.warn(msg, category=DeprecationWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"zoutPCQLJIk0","colab_type":"code","colab":{}},"source":["import keras.backend as K\n","import numpy as np\n","number_of_sample, max_number_of_words, word_vector_size = 40000, 100, 32\n","temp = bengali_news_after_preprocessing.loc[:number_of_sample-1,:max_number_of_words-1]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZMKHg3UDXKGz","colab_type":"text"},"source":["### Alternate method to get weird text "]},{"cell_type":"code","metadata":{"id":"IGq_URwATBS5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"6954a327-88ca-4e48-f760-5b485472bec9","executionInfo":{"status":"ok","timestamp":1560454883663,"user_tz":-360,"elapsed":1250,"user":{"displayName":"Pritom Mojumder","photoUrl":"https://lh5.googleusercontent.com/-f2ateZ-M7oE/AAAAAAAAAAI/AAAAAAAAAO0/QSPkIPgKOx4/s64/photo.jpg","userId":"01710067307887133491"}}},"source":["#ord('ী') #2496\n","#ord('ু') #2497\n","c = chr(2496)+chr(2497)\n","c"],"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'ীু'"]},"metadata":{"tags":[]},"execution_count":53}]},{"cell_type":"code","metadata":{"id":"NOhuZMPKKNG4","colab_type":"code","colab":{}},"source":["temp = temp.replace(['ঘস', 'ফগ', 'ঝবঃ', 'ঋন', 'ঊঘ', '\\u09e4', 'ওৎ', 'গথ', 'খঢ', 'ঝ’', 'ং', 'ঔ', 'ডড', 'গঘ','ঐব','ওঃ’ং','ুী','খষ','ি'], None)\n","X = np.zeros((number_of_sample, max_number_of_words, word_vector_size), dtype=K.floatx())\n","for i in temp.index:\n","  X[i,:,:] = loaded_model.wv[temp.loc[i,:]]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0EqTbmFsLDGd","colab_type":"text"},"source":["### preparing labels from csv"]},{"cell_type":"code","metadata":{"id":"zbz6a88_KTlW","colab_type":"code","colab":{}},"source":["bengali_news = pd.read_pickle('/content/gdrive/My Drive/Projects/Bengali Text Classification/40k_bangla_newspaper_article.p')\n","bengali_news_dataframe = pd.DataFrame(bengali_news)\n","y = bengali_news_dataframe['category']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jENsUpfoLzj7","colab_type":"code","colab":{}},"source":["from sklearn import preprocessing\n","import keras\n","import numpy as np\n","le = preprocessing.LabelEncoder()\n","le.fit(y)\n","enc = le.transform(y)\n","y = keras.utils.to_categorical(enc)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2VSBBww4YleT","colab_type":"text"},"source":["### Train, Validation and Test Split"]},{"cell_type":"code","metadata":{"id":"xFtKBeX7USSX","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","X_train, X_val, y_train, y_val = train_test_split(X, y, shuffle = True, test_size=0.125)\n","X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, shuffle = True, test_size=0.20)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3XlcaonuzHJJ","colab_type":"text"},"source":["### Training CNN"]},{"cell_type":"code","metadata":{"id":"Xni95IcIzDA8","colab_type":"code","colab":{}},"source":["from keras.models import Sequential\n","from keras.layers import Conv1D, Dropout, Dense, Flatten, LSTM, MaxPooling1D, Bidirectional\n","from keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping, TensorBoard\n","\n","\n","model = Sequential()\n","\n","model.add(Conv1D(32, kernel_size=3, activation='relu', padding='same',\n","                 input_shape=(max_number_of_words, word_vector_size)))\n","model.add(Conv1D(32, kernel_size=3, activation='relu', padding='same'))\n","model.add(Conv1D(32, kernel_size=3, activation='relu', padding='same'))\n","model.add(MaxPooling1D(pool_size=3))\n","model.add(Flatten())\n","model.add(Dense(256, activation='sigmoid'))\n","model.add(Dropout(0.2))\n","model.add(Dense(256, activation='sigmoid'))\n","model.add(Dropout(0.25))\n","model.add(Dense(256, activation='sigmoid'))\n","model.add(Dropout(0.25))\n","\n","model.add(Dense(13, activation='softmax'))\n","\n","model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001, decay=1e-6), metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cq5g8SmHG97m","colab_type":"code","outputId":"7a46db18-c46d-4ebc-fbeb-7a42f11923f7","executionInfo":{"status":"ok","timestamp":1560455198589,"user_tz":-360,"elapsed":1116,"user":{"displayName":"Pritom Mojumder","photoUrl":"https://lh5.googleusercontent.com/-f2ateZ-M7oE/AAAAAAAAAAI/AAAAAAAAAO0/QSPkIPgKOx4/s64/photo.jpg","userId":"01710067307887133491"}},"colab":{"base_uri":"https://localhost:8080/","height":568}},"source":["model.summary()"],"execution_count":60,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv1d_4 (Conv1D)            (None, 100, 32)           3104      \n","_________________________________________________________________\n","conv1d_5 (Conv1D)            (None, 100, 32)           3104      \n","_________________________________________________________________\n","conv1d_6 (Conv1D)            (None, 100, 32)           3104      \n","_________________________________________________________________\n","max_pooling1d_2 (MaxPooling1 (None, 33, 32)            0         \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 1056)              0         \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 256)               270592    \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 256)               65792     \n","_________________________________________________________________\n","dropout_5 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 256)               65792     \n","_________________________________________________________________\n","dropout_6 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 13)                3341      \n","=================================================================\n","Total params: 414,829\n","Trainable params: 414,829\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mghobpf7ZmNw","colab_type":"code","outputId":"23195aaf-059d-4257-dbd1-4e3500d5ae88","executionInfo":{"status":"ok","timestamp":1560455331017,"user_tz":-360,"elapsed":128098,"user":{"displayName":"Pritom Mojumder","photoUrl":"https://lh5.googleusercontent.com/-f2ateZ-M7oE/AAAAAAAAAAI/AAAAAAAAAO0/QSPkIPgKOx4/s64/photo.jpg","userId":"01710067307887133491"}},"colab":{"base_uri":"https://localhost:8080/","height":3590}},"source":["history = model.fit(X_train, y_train, batch_size= 500, shuffle=True, epochs= 100, validation_data=(X_val, y_val))"],"execution_count":61,"outputs":[{"output_type":"stream","text":["Train on 35000 samples, validate on 4000 samples\n","Epoch 1/100\n","35000/35000 [==============================] - 2s 69us/step - loss: 2.1549 - acc: 0.2504 - val_loss: 1.9087 - val_acc: 0.3150\n","Epoch 2/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 1.9307 - acc: 0.3135 - val_loss: 1.7530 - val_acc: 0.4253\n","Epoch 3/100\n","35000/35000 [==============================] - 1s 37us/step - loss: 1.6954 - acc: 0.4415 - val_loss: 1.4604 - val_acc: 0.5525\n","Epoch 4/100\n","35000/35000 [==============================] - 1s 37us/step - loss: 1.4199 - acc: 0.5769 - val_loss: 1.2266 - val_acc: 0.6448\n","Epoch 5/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 1.2339 - acc: 0.6359 - val_loss: 1.1050 - val_acc: 0.6573\n","Epoch 6/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 1.1409 - acc: 0.6533 - val_loss: 1.0346 - val_acc: 0.6743\n","Epoch 7/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 1.0754 - acc: 0.6705 - val_loss: 0.9858 - val_acc: 0.6930\n","Epoch 8/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 1.0270 - acc: 0.6853 - val_loss: 0.9507 - val_acc: 0.7020\n","Epoch 9/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 0.9875 - acc: 0.7020 - val_loss: 0.9180 - val_acc: 0.7245\n","Epoch 10/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 0.9522 - acc: 0.7141 - val_loss: 0.8891 - val_acc: 0.7358\n","Epoch 11/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 0.9200 - acc: 0.7283 - val_loss: 0.8576 - val_acc: 0.7507\n","Epoch 12/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 0.8920 - acc: 0.7355 - val_loss: 0.8378 - val_acc: 0.7570\n","Epoch 13/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 0.8625 - acc: 0.7447 - val_loss: 0.8202 - val_acc: 0.7573\n","Epoch 14/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.8447 - acc: 0.7500 - val_loss: 0.7979 - val_acc: 0.7587\n","Epoch 15/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.8228 - acc: 0.7535 - val_loss: 0.7843 - val_acc: 0.7615\n","Epoch 16/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.8065 - acc: 0.7577 - val_loss: 0.7745 - val_acc: 0.7635\n","Epoch 17/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.7876 - acc: 0.7611 - val_loss: 0.7697 - val_acc: 0.7582\n","Epoch 18/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.7708 - acc: 0.7626 - val_loss: 0.7457 - val_acc: 0.7670\n","Epoch 19/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.7550 - acc: 0.7667 - val_loss: 0.7344 - val_acc: 0.7688\n","Epoch 20/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 0.7409 - acc: 0.7695 - val_loss: 0.7273 - val_acc: 0.7693\n","Epoch 21/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.7238 - acc: 0.7763 - val_loss: 0.7164 - val_acc: 0.7715\n","Epoch 22/100\n","35000/35000 [==============================] - 1s 34us/step - loss: 0.7139 - acc: 0.7781 - val_loss: 0.7089 - val_acc: 0.7760\n","Epoch 23/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.7013 - acc: 0.7811 - val_loss: 0.7026 - val_acc: 0.7783\n","Epoch 24/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 0.6897 - acc: 0.7849 - val_loss: 0.6981 - val_acc: 0.7805\n","Epoch 25/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.6798 - acc: 0.7898 - val_loss: 0.6853 - val_acc: 0.7870\n","Epoch 26/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.6697 - acc: 0.7899 - val_loss: 0.6882 - val_acc: 0.7858\n","Epoch 27/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.6607 - acc: 0.7940 - val_loss: 0.6768 - val_acc: 0.7880\n","Epoch 28/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.6500 - acc: 0.7978 - val_loss: 0.6733 - val_acc: 0.7882\n","Epoch 29/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.6445 - acc: 0.7992 - val_loss: 0.6696 - val_acc: 0.7933\n","Epoch 30/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.6348 - acc: 0.8017 - val_loss: 0.6685 - val_acc: 0.7913\n","Epoch 31/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.6233 - acc: 0.8062 - val_loss: 0.6633 - val_acc: 0.7950\n","Epoch 32/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.6208 - acc: 0.8068 - val_loss: 0.6603 - val_acc: 0.7963\n","Epoch 33/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 0.6152 - acc: 0.8094 - val_loss: 0.6568 - val_acc: 0.7960\n","Epoch 34/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.6074 - acc: 0.8112 - val_loss: 0.6545 - val_acc: 0.7960\n","Epoch 35/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.5989 - acc: 0.8127 - val_loss: 0.6509 - val_acc: 0.7963\n","Epoch 36/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 0.5950 - acc: 0.8142 - val_loss: 0.6507 - val_acc: 0.7990\n","Epoch 37/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.5861 - acc: 0.8174 - val_loss: 0.6502 - val_acc: 0.7960\n","Epoch 38/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 0.5798 - acc: 0.8206 - val_loss: 0.6502 - val_acc: 0.7995\n","Epoch 39/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 0.5758 - acc: 0.8213 - val_loss: 0.6461 - val_acc: 0.7975\n","Epoch 40/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.5683 - acc: 0.8247 - val_loss: 0.6456 - val_acc: 0.7990\n","Epoch 41/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 0.5614 - acc: 0.8255 - val_loss: 0.6421 - val_acc: 0.8005\n","Epoch 42/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.5569 - acc: 0.8289 - val_loss: 0.6435 - val_acc: 0.8010\n","Epoch 43/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 0.5513 - acc: 0.8311 - val_loss: 0.6442 - val_acc: 0.7982\n","Epoch 44/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.5449 - acc: 0.8325 - val_loss: 0.6352 - val_acc: 0.8005\n","Epoch 45/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.5395 - acc: 0.8337 - val_loss: 0.6397 - val_acc: 0.8012\n","Epoch 46/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.5332 - acc: 0.8356 - val_loss: 0.6394 - val_acc: 0.8025\n","Epoch 47/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 0.5322 - acc: 0.8354 - val_loss: 0.6320 - val_acc: 0.8002\n","Epoch 48/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 0.5239 - acc: 0.8393 - val_loss: 0.6321 - val_acc: 0.8022\n","Epoch 49/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.5195 - acc: 0.8417 - val_loss: 0.6358 - val_acc: 0.8015\n","Epoch 50/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.5123 - acc: 0.8435 - val_loss: 0.6285 - val_acc: 0.8022\n","Epoch 51/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.5098 - acc: 0.8423 - val_loss: 0.6296 - val_acc: 0.8015\n","Epoch 52/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 0.5026 - acc: 0.8448 - val_loss: 0.6352 - val_acc: 0.8018\n","Epoch 53/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.4955 - acc: 0.8471 - val_loss: 0.6307 - val_acc: 0.8050\n","Epoch 54/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.4937 - acc: 0.8492 - val_loss: 0.6290 - val_acc: 0.8050\n","Epoch 55/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.4869 - acc: 0.8512 - val_loss: 0.6278 - val_acc: 0.8057\n","Epoch 56/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 0.4848 - acc: 0.8509 - val_loss: 0.6423 - val_acc: 0.8047\n","Epoch 57/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.4752 - acc: 0.8544 - val_loss: 0.6274 - val_acc: 0.8057\n","Epoch 58/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.4751 - acc: 0.8549 - val_loss: 0.6297 - val_acc: 0.8053\n","Epoch 59/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.4664 - acc: 0.8557 - val_loss: 0.6362 - val_acc: 0.8065\n","Epoch 60/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.4661 - acc: 0.8571 - val_loss: 0.6277 - val_acc: 0.8067\n","Epoch 61/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.4626 - acc: 0.8582 - val_loss: 0.6292 - val_acc: 0.8078\n","Epoch 62/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 0.4542 - acc: 0.8610 - val_loss: 0.6346 - val_acc: 0.8063\n","Epoch 63/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 0.4463 - acc: 0.8660 - val_loss: 0.6278 - val_acc: 0.8043\n","Epoch 64/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 0.4485 - acc: 0.8631 - val_loss: 0.6313 - val_acc: 0.8102\n","Epoch 65/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.4402 - acc: 0.8652 - val_loss: 0.6292 - val_acc: 0.8065\n","Epoch 66/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.4356 - acc: 0.8683 - val_loss: 0.6279 - val_acc: 0.8078\n","Epoch 67/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.4316 - acc: 0.8697 - val_loss: 0.6396 - val_acc: 0.8085\n","Epoch 68/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.4263 - acc: 0.8714 - val_loss: 0.6489 - val_acc: 0.8055\n","Epoch 69/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.4238 - acc: 0.8722 - val_loss: 0.6322 - val_acc: 0.8090\n","Epoch 70/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.4171 - acc: 0.8747 - val_loss: 0.6343 - val_acc: 0.8105\n","Epoch 71/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 0.4138 - acc: 0.8737 - val_loss: 0.6363 - val_acc: 0.8095\n","Epoch 72/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.4091 - acc: 0.8754 - val_loss: 0.6351 - val_acc: 0.8120\n","Epoch 73/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 0.4056 - acc: 0.8777 - val_loss: 0.6427 - val_acc: 0.8097\n","Epoch 74/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.3988 - acc: 0.8800 - val_loss: 0.6393 - val_acc: 0.8088\n","Epoch 75/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.3940 - acc: 0.8821 - val_loss: 0.6430 - val_acc: 0.8077\n","Epoch 76/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 0.3938 - acc: 0.8822 - val_loss: 0.6437 - val_acc: 0.8082\n","Epoch 77/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 0.3844 - acc: 0.8851 - val_loss: 0.6519 - val_acc: 0.8060\n","Epoch 78/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.3833 - acc: 0.8864 - val_loss: 0.6469 - val_acc: 0.8097\n","Epoch 79/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 0.3773 - acc: 0.8869 - val_loss: 0.6476 - val_acc: 0.8100\n","Epoch 80/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 0.3743 - acc: 0.8864 - val_loss: 0.6432 - val_acc: 0.8080\n","Epoch 81/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 0.3676 - acc: 0.8891 - val_loss: 0.6453 - val_acc: 0.8090\n","Epoch 82/100\n","35000/35000 [==============================] - 1s 37us/step - loss: 0.3653 - acc: 0.8920 - val_loss: 0.6547 - val_acc: 0.8130\n","Epoch 83/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 0.3624 - acc: 0.8910 - val_loss: 0.6539 - val_acc: 0.8072\n","Epoch 84/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 0.3570 - acc: 0.8920 - val_loss: 0.6564 - val_acc: 0.8070\n","Epoch 85/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 0.3549 - acc: 0.8944 - val_loss: 0.6587 - val_acc: 0.8052\n","Epoch 86/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.3506 - acc: 0.8958 - val_loss: 0.6633 - val_acc: 0.8083\n","Epoch 87/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 0.3420 - acc: 0.8985 - val_loss: 0.6598 - val_acc: 0.8088\n","Epoch 88/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 0.3405 - acc: 0.8984 - val_loss: 0.6592 - val_acc: 0.8065\n","Epoch 89/100\n","35000/35000 [==============================] - 1s 37us/step - loss: 0.3354 - acc: 0.8991 - val_loss: 0.6745 - val_acc: 0.8048\n","Epoch 90/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 0.3292 - acc: 0.9025 - val_loss: 0.6643 - val_acc: 0.8063\n","Epoch 91/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 0.3288 - acc: 0.9014 - val_loss: 0.6708 - val_acc: 0.8072\n","Epoch 92/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.3225 - acc: 0.9048 - val_loss: 0.6694 - val_acc: 0.8070\n","Epoch 93/100\n","35000/35000 [==============================] - 1s 35us/step - loss: 0.3216 - acc: 0.9049 - val_loss: 0.6825 - val_acc: 0.8063\n","Epoch 94/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 0.3135 - acc: 0.9065 - val_loss: 0.6766 - val_acc: 0.8070\n","Epoch 95/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 0.3117 - acc: 0.9068 - val_loss: 0.6819 - val_acc: 0.8078\n","Epoch 96/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 0.3072 - acc: 0.9085 - val_loss: 0.6909 - val_acc: 0.8082\n","Epoch 97/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 0.3061 - acc: 0.9089 - val_loss: 0.6907 - val_acc: 0.8073\n","Epoch 98/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 0.2996 - acc: 0.9106 - val_loss: 0.6876 - val_acc: 0.8060\n","Epoch 99/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 0.2956 - acc: 0.9130 - val_loss: 0.6875 - val_acc: 0.8073\n","Epoch 100/100\n","35000/35000 [==============================] - 1s 36us/step - loss: 0.2899 - acc: 0.9146 - val_loss: 0.6968 - val_acc: 0.8080\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vPP36yLOaKbO","colab_type":"code","colab":{}},"source":["predicts = model.predict(X_test)\n","import numpy as np\n","def decode(le, one_hot):\n","    dec = np.argmax(one_hot, axis=1)\n","    return le.inverse_transform(dec)\n","y_test = decode(le, y_test)\n","y_preds = decode(le, predicts)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JHNM_Wbh4rpQ","colab_type":"code","outputId":"5a1311ac-3576-43a1-f4f8-dfa72ec39bb3","executionInfo":{"status":"ok","timestamp":1560455341522,"user_tz":-360,"elapsed":1217,"user":{"displayName":"Pritom Mojumder","photoUrl":"https://lh5.googleusercontent.com/-f2ateZ-M7oE/AAAAAAAAAAI/AAAAAAAAAO0/QSPkIPgKOx4/s64/photo.jpg","userId":"01710067307887133491"}},"colab":{"base_uri":"https://localhost:8080/","height":621}},"source":["from sklearn import metrics\n","\n","print(metrics.accuracy_score(y_test, y_preds))\n","\n","print(metrics.confusion_matrix(y_test, y_preds))\n","\n","print(metrics.classification_report(y_test, y_preds))"],"execution_count":63,"outputs":[{"output_type":"stream","text":["0.802\n","[[  0   2   0   0   0   0   0   5   0   2   0   0]\n"," [  0 251   0   9   2   1   4   3   0  14   0   2]\n"," [  0   5   0   0   0   2   0   0   0   0   0   0]\n"," [  0  13   0 115   1   0   0   0   0   7   0   4]\n"," [  0   3   0   0   7   0   0   3   0   2   0   0]\n"," [  0   2   0   0   0  53   0   1   0   0   0   1]\n"," [  0   6   0   1   0   1  31   0   0   9   0   0]\n"," [  0   2   0   0   2   1   0  19   0   5   1   2]\n"," [  0   2   0   0   0   1   2   0   0   1   1   1]\n"," [  3  28   0  12   3   1   3   7   0 216   0   4]\n"," [  0   0   0   0   0   3   0   0   0   0  79   0]\n"," [  0   0   0   3   2   1   0   1   0   1   0  31]]\n","                    precision    recall  f1-score   support\n","\n","art-and-literature       0.00      0.00      0.00         9\n","        bangladesh       0.80      0.88      0.84       286\n","       durporobash       0.00      0.00      0.00         7\n","           economy       0.82      0.82      0.82       140\n","         education       0.41      0.47      0.44        15\n","     entertainment       0.83      0.93      0.88        57\n","     international       0.78      0.65      0.70        48\n","        life-style       0.49      0.59      0.54        32\n","      northamerica       0.00      0.00      0.00         8\n","           opinion       0.84      0.78      0.81       277\n","            sports       0.98      0.96      0.97        82\n","        technology       0.69      0.79      0.74        39\n","\n","          accuracy                           0.80      1000\n","         macro avg       0.55      0.57      0.56      1000\n","      weighted avg       0.79      0.80      0.79      1000\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n","  'precision', 'predicted', average, warn_for)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"gg3kjzUjP1XJ","colab_type":"code","colab":{}},"source":["accuracy, val_accuracy = np.array(history.history[\"acc\"]), np.array(history.history[\"val_acc\"])\n","accuracy, val_accuracy = accuracy.reshape(100,1), val_accuracy.reshape(100,1)\n","accuracies = np.concatenate((accuracy,val_accuracy),axis=1)\n","np.savetxt('/content/gdrive/My Drive/Projects/Bengali Text Classification/temp.csv',accuracies,delimiter=\",\")"],"execution_count":0,"outputs":[]}]}