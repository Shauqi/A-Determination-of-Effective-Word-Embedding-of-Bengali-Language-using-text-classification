{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CgOelJ11JvRF"
   },
   "source": [
    "### Converting preprocessed text into vectors using fasttext embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18670,
     "status": "ok",
     "timestamp": 1560094777544,
     "user": {
      "displayName": "Mahmudul Hasan",
      "photoUrl": "",
      "userId": "10838423032874605851"
     },
     "user_tz": -360
    },
    "id": "SXe8uEAgIRjR",
    "outputId": "b9f5eb95-28fb-461b-8668-ee9977f2495c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "drive.mount('/content/gdrive')\n",
    "bengali_news_after_preprocessing = pd.read_pickle('/content/gdrive/My Drive/Projects/Bengali Text Classification/Bengali_Text_after_preprocessing.pkl')\n",
    "from sklearn.externals import joblib\n",
    "filename = '/content/gdrive/My Drive/Projects/Bengali Text Classification/fastText_Bangla_content_full.sav'\n",
    "loaded_model = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zoutPCQLJIk0"
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import numpy as np\n",
    "number_of_sample, max_number_of_words, word_vector_size = 40000, 50, 32\n",
    "temp = bengali_news_after_preprocessing.loc[:number_of_sample-1,:max_number_of_words-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NOhuZMPKKNG4"
   },
   "outputs": [],
   "source": [
    "temp = temp.replace(['ঘস', 'ফগ', 'ঝবঃ', 'ঋন', 'ঊঘ', '\\u09e4', 'ওৎ', 'গথ', 'খঢ', 'ঝ’', ' ং', 'ঔ', 'ডড', 'গঘ'], None)\n",
    "X = np.zeros((number_of_sample, max_number_of_words, word_vector_size), dtype=K.floatx())\n",
    "for i in temp.index:\n",
    "  X[i,:,:] = loaded_model.wv[temp.loc[i,:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0EqTbmFsLDGd"
   },
   "source": [
    "### preparing labels from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zbz6a88_KTlW"
   },
   "outputs": [],
   "source": [
    "bengali_news = pd.read_pickle('/content/gdrive/My Drive/Projects/Bengali Text Classification/40k_bangla_newspaper_article.p')\n",
    "bengali_news_dataframe = pd.DataFrame(bengali_news)\n",
    "y = bengali_news_dataframe['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jENsUpfoLzj7"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import keras\n",
    "import numpy as np\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "enc = le.transform(y)\n",
    "y = keras.utils.to_categorical(enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2VSBBww4YleT"
   },
   "source": [
    "### Train, Validation and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xFtKBeX7USSX"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, shuffle = True, test_size=0.125)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, shuffle = True, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3XlcaonuzHJJ"
   },
   "source": [
    "### Training CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xni95IcIzDA8"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Dropout, Dense, Flatten, LSTM, MaxPooling1D, Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(32, kernel_size=3, activation='relu', padding='same',\n",
    "                 input_shape=(max_number_of_words, word_vector_size)))\n",
    "model.add(Conv1D(32, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(Conv1D(32, kernel_size=3, activation='relu', padding='same'))\n",
    "model.add(MaxPooling1D(pool_size=3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='sigmoid'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(256, activation='sigmoid'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(13, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001, decay=1e-6), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 791,
     "status": "ok",
     "timestamp": 1560098458352,
     "user": {
      "displayName": "Mahmudul Hasan",
      "photoUrl": "",
      "userId": "10838423032874605851"
     },
     "user_tz": -360
    },
    "id": "Cq5g8SmHG97m",
    "outputId": "d4c1d563-fc1f-4648-95f4-7a30b9868602"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_4 (Conv1D)            (None, 50, 32)            3104      \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 50, 32)            3104      \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 50, 32)            3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 16, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 13)                3341      \n",
      "=================================================================\n",
      "Total params: 275,565\n",
      "Trainable params: 275,565\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3434
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 63808,
     "status": "ok",
     "timestamp": 1560098528074,
     "user": {
      "displayName": "Mahmudul Hasan",
      "photoUrl": "",
      "userId": "10838423032874605851"
     },
     "user_tz": -360
    },
    "id": "mghobpf7ZmNw",
    "outputId": "d68ddbb9-95ee-4847-9f83-128474563ac5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35000 samples, validate on 4000 samples\n",
      "Epoch 1/100\n",
      "35000/35000 [==============================] - 4s 125us/step - loss: 2.2812 - acc: 0.2239 - val_loss: 1.9531 - val_acc: 0.3085\n",
      "Epoch 2/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 1.9797 - acc: 0.2971 - val_loss: 1.8896 - val_acc: 0.4240\n",
      "Epoch 3/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 1.8560 - acc: 0.3987 - val_loss: 1.7179 - val_acc: 0.4570\n",
      "Epoch 4/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 1.6986 - acc: 0.4665 - val_loss: 1.5960 - val_acc: 0.4662\n",
      "Epoch 5/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 1.5533 - acc: 0.5233 - val_loss: 1.4176 - val_acc: 0.6043\n",
      "Epoch 6/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 1.3781 - acc: 0.6135 - val_loss: 1.2662 - val_acc: 0.6255\n",
      "Epoch 7/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 1.2550 - acc: 0.6385 - val_loss: 1.1677 - val_acc: 0.6380\n",
      "Epoch 8/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 1.1717 - acc: 0.6527 - val_loss: 1.1032 - val_acc: 0.6562\n",
      "Epoch 9/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 1.1130 - acc: 0.6690 - val_loss: 1.0552 - val_acc: 0.6795\n",
      "Epoch 10/100\n",
      "35000/35000 [==============================] - 1s 16us/step - loss: 1.0652 - acc: 0.6860 - val_loss: 1.0140 - val_acc: 0.6943\n",
      "Epoch 11/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 1.0309 - acc: 0.6975 - val_loss: 0.9794 - val_acc: 0.7018\n",
      "Epoch 12/100\n",
      "35000/35000 [==============================] - 1s 16us/step - loss: 0.9952 - acc: 0.7085 - val_loss: 0.9515 - val_acc: 0.7078\n",
      "Epoch 13/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.9686 - acc: 0.7143 - val_loss: 0.9309 - val_acc: 0.7105\n",
      "Epoch 14/100\n",
      "35000/35000 [==============================] - 1s 16us/step - loss: 0.9431 - acc: 0.7201 - val_loss: 0.9111 - val_acc: 0.7142\n",
      "Epoch 15/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.9288 - acc: 0.7225 - val_loss: 0.8961 - val_acc: 0.7175\n",
      "Epoch 16/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.9111 - acc: 0.7248 - val_loss: 0.8822 - val_acc: 0.7185\n",
      "Epoch 17/100\n",
      "35000/35000 [==============================] - 1s 16us/step - loss: 0.8966 - acc: 0.7276 - val_loss: 0.8677 - val_acc: 0.7225\n",
      "Epoch 18/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.8821 - acc: 0.7284 - val_loss: 0.8575 - val_acc: 0.7245\n",
      "Epoch 19/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.8669 - acc: 0.7336 - val_loss: 0.8479 - val_acc: 0.7272\n",
      "Epoch 20/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.8556 - acc: 0.7357 - val_loss: 0.8383 - val_acc: 0.7283\n",
      "Epoch 21/100\n",
      "35000/35000 [==============================] - 1s 16us/step - loss: 0.8471 - acc: 0.7366 - val_loss: 0.8266 - val_acc: 0.7307\n",
      "Epoch 22/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.8318 - acc: 0.7413 - val_loss: 0.8176 - val_acc: 0.7330\n",
      "Epoch 23/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.8229 - acc: 0.7426 - val_loss: 0.8090 - val_acc: 0.7343\n",
      "Epoch 24/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.8138 - acc: 0.7451 - val_loss: 0.8010 - val_acc: 0.7360\n",
      "Epoch 25/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.8004 - acc: 0.7462 - val_loss: 0.7935 - val_acc: 0.7393\n",
      "Epoch 26/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.7953 - acc: 0.7490 - val_loss: 0.7874 - val_acc: 0.7405\n",
      "Epoch 27/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.7856 - acc: 0.7518 - val_loss: 0.7830 - val_acc: 0.7422\n",
      "Epoch 28/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.7791 - acc: 0.7530 - val_loss: 0.7755 - val_acc: 0.7415\n",
      "Epoch 29/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.7704 - acc: 0.7556 - val_loss: 0.7721 - val_acc: 0.7418\n",
      "Epoch 30/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.7618 - acc: 0.7566 - val_loss: 0.7679 - val_acc: 0.7410\n",
      "Epoch 31/100\n",
      "35000/35000 [==============================] - 1s 16us/step - loss: 0.7553 - acc: 0.7571 - val_loss: 0.7598 - val_acc: 0.7465\n",
      "Epoch 32/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.7522 - acc: 0.7601 - val_loss: 0.7593 - val_acc: 0.7445\n",
      "Epoch 33/100\n",
      "35000/35000 [==============================] - 1s 16us/step - loss: 0.7447 - acc: 0.7603 - val_loss: 0.7516 - val_acc: 0.7522\n",
      "Epoch 34/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.7366 - acc: 0.7656 - val_loss: 0.7512 - val_acc: 0.7503\n",
      "Epoch 35/100\n",
      "35000/35000 [==============================] - 1s 16us/step - loss: 0.7327 - acc: 0.7645 - val_loss: 0.7434 - val_acc: 0.7525\n",
      "Epoch 36/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.7268 - acc: 0.7676 - val_loss: 0.7383 - val_acc: 0.7543\n",
      "Epoch 37/100\n",
      "35000/35000 [==============================] - 1s 18us/step - loss: 0.7172 - acc: 0.7715 - val_loss: 0.7354 - val_acc: 0.7577\n",
      "Epoch 38/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.7171 - acc: 0.7707 - val_loss: 0.7314 - val_acc: 0.7580\n",
      "Epoch 39/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.7070 - acc: 0.7709 - val_loss: 0.7296 - val_acc: 0.7568\n",
      "Epoch 40/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.7052 - acc: 0.7721 - val_loss: 0.7248 - val_acc: 0.7572\n",
      "Epoch 41/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.6999 - acc: 0.7731 - val_loss: 0.7239 - val_acc: 0.7615\n",
      "Epoch 42/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.6942 - acc: 0.7770 - val_loss: 0.7250 - val_acc: 0.7588\n",
      "Epoch 43/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.6910 - acc: 0.7779 - val_loss: 0.7197 - val_acc: 0.7650\n",
      "Epoch 44/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.6878 - acc: 0.7788 - val_loss: 0.7140 - val_acc: 0.7655\n",
      "Epoch 45/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.6798 - acc: 0.7807 - val_loss: 0.7160 - val_acc: 0.7648\n",
      "Epoch 46/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.6780 - acc: 0.7796 - val_loss: 0.7136 - val_acc: 0.7640\n",
      "Epoch 47/100\n",
      "35000/35000 [==============================] - 1s 16us/step - loss: 0.6709 - acc: 0.7852 - val_loss: 0.7063 - val_acc: 0.7682\n",
      "Epoch 48/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.6659 - acc: 0.7861 - val_loss: 0.7044 - val_acc: 0.7683\n",
      "Epoch 49/100\n",
      "35000/35000 [==============================] - 1s 16us/step - loss: 0.6638 - acc: 0.7863 - val_loss: 0.7073 - val_acc: 0.7672\n",
      "Epoch 50/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.6601 - acc: 0.7905 - val_loss: 0.7030 - val_acc: 0.7705\n",
      "Epoch 51/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.6544 - acc: 0.7913 - val_loss: 0.7068 - val_acc: 0.7665\n",
      "Epoch 52/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.6503 - acc: 0.7918 - val_loss: 0.6979 - val_acc: 0.7702\n",
      "Epoch 53/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.6456 - acc: 0.7918 - val_loss: 0.6962 - val_acc: 0.7712\n",
      "Epoch 54/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.6453 - acc: 0.7935 - val_loss: 0.6965 - val_acc: 0.7727\n",
      "Epoch 55/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.6402 - acc: 0.7940 - val_loss: 0.6925 - val_acc: 0.7750\n",
      "Epoch 56/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.6373 - acc: 0.7946 - val_loss: 0.6918 - val_acc: 0.7768\n",
      "Epoch 57/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.6311 - acc: 0.7987 - val_loss: 0.6880 - val_acc: 0.7760\n",
      "Epoch 58/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.6268 - acc: 0.7990 - val_loss: 0.6893 - val_acc: 0.7770\n",
      "Epoch 59/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.6255 - acc: 0.8001 - val_loss: 0.6872 - val_acc: 0.7760\n",
      "Epoch 60/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.6218 - acc: 0.8013 - val_loss: 0.6879 - val_acc: 0.7772\n",
      "Epoch 61/100\n",
      "35000/35000 [==============================] - 1s 16us/step - loss: 0.6154 - acc: 0.8038 - val_loss: 0.6849 - val_acc: 0.7775\n",
      "Epoch 62/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.6118 - acc: 0.8051 - val_loss: 0.6812 - val_acc: 0.7737\n",
      "Epoch 63/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.6126 - acc: 0.8040 - val_loss: 0.6865 - val_acc: 0.7758\n",
      "Epoch 64/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.6110 - acc: 0.8048 - val_loss: 0.6806 - val_acc: 0.7747\n",
      "Epoch 65/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.6029 - acc: 0.8069 - val_loss: 0.6800 - val_acc: 0.7780\n",
      "Epoch 66/100\n",
      "35000/35000 [==============================] - 1s 16us/step - loss: 0.6000 - acc: 0.8085 - val_loss: 0.6773 - val_acc: 0.7810\n",
      "Epoch 67/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.5994 - acc: 0.8087 - val_loss: 0.6803 - val_acc: 0.7807\n",
      "Epoch 68/100\n",
      "35000/35000 [==============================] - 1s 16us/step - loss: 0.5941 - acc: 0.8114 - val_loss: 0.6778 - val_acc: 0.7765\n",
      "Epoch 69/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.5932 - acc: 0.8119 - val_loss: 0.6748 - val_acc: 0.7805\n",
      "Epoch 70/100\n",
      "35000/35000 [==============================] - 1s 16us/step - loss: 0.5917 - acc: 0.8125 - val_loss: 0.6752 - val_acc: 0.7775\n",
      "Epoch 71/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.5864 - acc: 0.8128 - val_loss: 0.6744 - val_acc: 0.7768\n",
      "Epoch 72/100\n",
      "35000/35000 [==============================] - 1s 18us/step - loss: 0.5847 - acc: 0.8144 - val_loss: 0.6754 - val_acc: 0.7768\n",
      "Epoch 73/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.5804 - acc: 0.8145 - val_loss: 0.6724 - val_acc: 0.7800\n",
      "Epoch 74/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.5764 - acc: 0.8161 - val_loss: 0.6735 - val_acc: 0.7795\n",
      "Epoch 75/100\n",
      "35000/35000 [==============================] - 1s 16us/step - loss: 0.5711 - acc: 0.8194 - val_loss: 0.6707 - val_acc: 0.7788\n",
      "Epoch 76/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.5731 - acc: 0.8197 - val_loss: 0.6702 - val_acc: 0.7802\n",
      "Epoch 77/100\n",
      "35000/35000 [==============================] - 1s 16us/step - loss: 0.5692 - acc: 0.8203 - val_loss: 0.6672 - val_acc: 0.7800\n",
      "Epoch 78/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.5634 - acc: 0.8229 - val_loss: 0.6687 - val_acc: 0.7825\n",
      "Epoch 79/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.5611 - acc: 0.8220 - val_loss: 0.6685 - val_acc: 0.7792\n",
      "Epoch 80/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.5571 - acc: 0.8238 - val_loss: 0.6702 - val_acc: 0.7830\n",
      "Epoch 81/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.5554 - acc: 0.8233 - val_loss: 0.6668 - val_acc: 0.7840\n",
      "Epoch 82/100\n",
      "35000/35000 [==============================] - 1s 16us/step - loss: 0.5529 - acc: 0.8260 - val_loss: 0.6686 - val_acc: 0.7847\n",
      "Epoch 83/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.5491 - acc: 0.8255 - val_loss: 0.6673 - val_acc: 0.7853\n",
      "Epoch 84/100\n",
      "35000/35000 [==============================] - 1s 16us/step - loss: 0.5447 - acc: 0.8290 - val_loss: 0.6694 - val_acc: 0.7850\n",
      "Epoch 85/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.5458 - acc: 0.8276 - val_loss: 0.6655 - val_acc: 0.7853\n",
      "Epoch 86/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.5428 - acc: 0.8300 - val_loss: 0.6696 - val_acc: 0.7837\n",
      "Epoch 87/100\n",
      "35000/35000 [==============================] - 1s 16us/step - loss: 0.5401 - acc: 0.8285 - val_loss: 0.6650 - val_acc: 0.7852\n",
      "Epoch 88/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.5360 - acc: 0.8313 - val_loss: 0.6671 - val_acc: 0.7842\n",
      "Epoch 89/100\n",
      "35000/35000 [==============================] - 1s 16us/step - loss: 0.5325 - acc: 0.8315 - val_loss: 0.6724 - val_acc: 0.7857\n",
      "Epoch 90/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.5314 - acc: 0.8324 - val_loss: 0.6656 - val_acc: 0.7858\n",
      "Epoch 91/100\n",
      "35000/35000 [==============================] - 1s 16us/step - loss: 0.5291 - acc: 0.8323 - val_loss: 0.6666 - val_acc: 0.7885\n",
      "Epoch 92/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.5217 - acc: 0.8356 - val_loss: 0.6644 - val_acc: 0.7877\n",
      "Epoch 93/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.5237 - acc: 0.8358 - val_loss: 0.6690 - val_acc: 0.7890\n",
      "Epoch 94/100\n",
      "35000/35000 [==============================] - 1s 16us/step - loss: 0.5196 - acc: 0.8359 - val_loss: 0.6676 - val_acc: 0.7875\n",
      "Epoch 95/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.5196 - acc: 0.8360 - val_loss: 0.6712 - val_acc: 0.7883\n",
      "Epoch 96/100\n",
      "35000/35000 [==============================] - 1s 16us/step - loss: 0.5130 - acc: 0.8376 - val_loss: 0.6637 - val_acc: 0.7877\n",
      "Epoch 97/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.5156 - acc: 0.8383 - val_loss: 0.6644 - val_acc: 0.7877\n",
      "Epoch 98/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.5087 - acc: 0.8421 - val_loss: 0.6687 - val_acc: 0.7860\n",
      "Epoch 99/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.5046 - acc: 0.8418 - val_loss: 0.6653 - val_acc: 0.7865\n",
      "Epoch 100/100\n",
      "35000/35000 [==============================] - 1s 17us/step - loss: 0.5009 - acc: 0.8430 - val_loss: 0.6688 - val_acc: 0.7855\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size= 500, shuffle=True, epochs= 100, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vPP36yLOaKbO"
   },
   "outputs": [],
   "source": [
    "predicts = model.predict(X_test)\n",
    "import numpy as np\n",
    "def decode(le, one_hot):\n",
    "    dec = np.argmax(one_hot, axis=1)\n",
    "    return le.inverse_transform(dec)\n",
    "y_test = decode(le, y_test)\n",
    "y_preds = decode(le, predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 615
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 760,
     "status": "ok",
     "timestamp": 1560098542912,
     "user": {
      "displayName": "Mahmudul Hasan",
      "photoUrl": "",
      "userId": "10838423032874605851"
     },
     "user_tz": -360
    },
    "id": "JHNM_Wbh4rpQ",
    "outputId": "70df3a2d-2ef7-4ba1-b49f-1f2c9ffc9568"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.806\n",
      "[[  0   0   0   0   0   1   0   1   0   8   0   0]\n",
      " [  0 245   0  11   2   2   5   1   0  33   1   2]\n",
      " [  0   2   0   0   0   1   0   0   0   2   0   0]\n",
      " [  0   5   0  93   0   1   2   0   0   9   0   2]\n",
      " [  0   1   0   1   7   1   0   0   0   3   0   0]\n",
      " [  0   6   0   0   0  55   1   0   0   1   1   0]\n",
      " [  0   5   0   0   0   2  27   0   0  10   1   1]\n",
      " [  0   1   0   2   0   2   0  11   0   5   1   2]\n",
      " [  0   0   0   0   0   0   2   0   0   3   0   0]\n",
      " [  0  19   0   7   0   2   5   4   0 239   1   2]\n",
      " [  0   0   0   0   0   1   2   0   0   1  78   0]\n",
      " [  0   2   0   2   0   0   0   1   0   2   0  51]]\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "art-and-literature       0.00      0.00      0.00        10\n",
      "        bangladesh       0.86      0.81      0.83       302\n",
      "       durporobash       0.00      0.00      0.00         5\n",
      "           economy       0.80      0.83      0.82       112\n",
      "         education       0.78      0.54      0.64        13\n",
      "     entertainment       0.81      0.86      0.83        64\n",
      "     international       0.61      0.59      0.60        46\n",
      "        life-style       0.61      0.46      0.52        24\n",
      "      northamerica       0.00      0.00      0.00         5\n",
      "           opinion       0.76      0.86      0.80       279\n",
      "            sports       0.94      0.95      0.95        82\n",
      "        technology       0.85      0.88      0.86        58\n",
      "\n",
      "          accuracy                           0.81      1000\n",
      "         macro avg       0.58      0.56      0.57      1000\n",
      "      weighted avg       0.79      0.81      0.80      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.accuracy_score(y_test, y_preds))\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, y_preds))\n",
    "\n",
    "print(metrics.classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gg3kjzUjP1XJ"
   },
   "outputs": [],
   "source": [
    "accuracy, val_accuracy = np.array(history.history[\"acc\"]), np.array(history.history[\"val_acc\"])\n",
    "accuracy, val_accuracy = accuracy.reshape(100,1), val_accuracy.reshape(100,1)\n",
    "accuracies = np.concatenate((accuracy,val_accuracy),axis=1)\n",
    "np.savetxt('/content/gdrive/My Drive/Projects/Bengali Text Classification/temp.csv',accuracies,delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FastText + CNN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
