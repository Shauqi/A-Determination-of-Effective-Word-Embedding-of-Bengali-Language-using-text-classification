{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FastText + Bi-Directional LSTM.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"FZvP_g-SV47j","colab_type":"code","outputId":"cda83e6f-7619-4f25-9af2-e612f325d925","executionInfo":{"status":"ok","timestamp":1560246570260,"user_tz":-360,"elapsed":51634,"user":{"displayName":"Mahmudul Hasan","photoUrl":"","userId":"10838423032874605851"}},"colab":{"base_uri":"https://localhost:8080/","height":156}},"source":["from google.colab import drive\n","import numpy as np\n","import pandas as pd\n","drive.mount('/content/gdrive')\n","bengali_news_after_preprocessing = pd.read_pickle('/content/gdrive/My Drive/Projects/Bengali Text Classification/Bengali_Text_after_preprocessing.pkl')\n","from sklearn.externals import joblib\n","filename = '/content/gdrive/My Drive/Projects/Bengali Text Classification/fastText_Bangla_content_full.sav'\n","loaded_model = joblib.load(filename)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n","  warnings.warn(msg, category=DeprecationWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Bh152mlTWClV","colab_type":"code","outputId":"e7dbdea8-1ced-44bb-c77c-d378171c4234","executionInfo":{"status":"ok","timestamp":1560246581381,"user_tz":-360,"elapsed":1911,"user":{"displayName":"Mahmudul Hasan","photoUrl":"","userId":"10838423032874605851"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import keras.backend as K\n","import numpy as np\n","number_of_sample, max_number_of_words, word_vector_size = 40000, 50, 32\n","temp = bengali_news_after_preprocessing.loc[:number_of_sample-1,:max_number_of_words-1]"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"BL1dPKt5WNAp","colab_type":"code","colab":{}},"source":["temp = temp.replace(['ঘস', 'ফগ', 'ঝবঃ', 'ঋন', 'ঊঘ', '\\u09e4', 'ওৎ', 'গথ', 'খঢ', 'ঝ’', ' ং', 'ঔ', 'ডড', 'গঘ'], None)\n","X = np.zeros((number_of_sample, max_number_of_words, word_vector_size), dtype=K.floatx())\n","for i in temp.index:\n","  X[i,:,:] = loaded_model.wv[temp.loc[i,:]]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kx4gwqnUWO8R","colab_type":"code","colab":{}},"source":["bengali_news = pd.read_pickle('/content/gdrive/My Drive/Projects/Bengali Text Classification/40k_bangla_newspaper_article.p')\n","bengali_news_dataframe = pd.DataFrame(bengali_news)\n","y = bengali_news_dataframe['category']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pDj7CROuWRrp","colab_type":"code","colab":{}},"source":["from sklearn import preprocessing\n","import keras\n","import numpy as np\n","le = preprocessing.LabelEncoder()\n","le.fit(y)\n","enc = le.transform(y)\n","y = keras.utils.to_categorical(enc)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ltHADvLlWVsg","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","X_train, X_val, y_train, y_val = train_test_split(X, y, shuffle = True, test_size=0.125)\n","X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, shuffle = True, test_size=0.20)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"g2Z737RiWYM4","colab_type":"code","colab":{}},"source":["from keras.models import Sequential\n","from keras.layers import Conv1D, Dropout, Dense, Flatten, LSTM, MaxPooling1D, Bidirectional\n","from keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping, TensorBoard\n","\n","\n","model = Sequential()\n","\n","model.add(Bidirectional(LSTM(512, dropout=0.2, recurrent_dropout=0.3), input_shape=(max_number_of_words, word_vector_size)))\n","model.add(Dense(256, activation='sigmoid'))\n","model.add(Dropout(0.2))\n","model.add(Dense(256, activation='sigmoid'))\n","model.add(Dropout(0.25))\n","model.add(Dense(256, activation='sigmoid'))\n","model.add(Dropout(0.25))\n","\n","model.add(Dense(13, activation='softmax'))\n","\n","model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001, decay=1e-6), metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9JD8UfRZWdcI","colab_type":"code","outputId":"c3ab90ee-aaa9-4aa1-c4ce-0f4f32a28f23","executionInfo":{"status":"ok","timestamp":1560246956018,"user_tz":-360,"elapsed":1314,"user":{"displayName":"Mahmudul Hasan","photoUrl":"","userId":"10838423032874605851"}},"colab":{"base_uri":"https://localhost:8080/","height":408}},"source":["model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","bidirectional_10 (Bidirectio (None, 1024)              2232320   \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 256)               262400    \n","_________________________________________________________________\n","dropout_7 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_10 (Dense)             (None, 256)               65792     \n","_________________________________________________________________\n","dropout_8 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_11 (Dense)             (None, 256)               65792     \n","_________________________________________________________________\n","dropout_9 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_12 (Dense)             (None, 13)                3341      \n","=================================================================\n","Total params: 2,629,645\n","Trainable params: 2,629,645\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bkrt1heEWoWg","colab_type":"code","outputId":"e20e261d-fc9b-4604-88c5-1458b34e1ed9","executionInfo":{"status":"ok","timestamp":1560250449298,"user_tz":-360,"elapsed":3494567,"user":{"displayName":"Mahmudul Hasan","photoUrl":"","userId":"10838423032874605851"}},"colab":{"base_uri":"https://localhost:8080/","height":3434}},"source":["history = model.fit(X_train, y_train, batch_size= 500, shuffle=True, epochs= 100, validation_data=(X_val, y_val))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 35000 samples, validate on 4000 samples\n","Epoch 1/100\n","35000/35000 [==============================] - 35s 1ms/step - loss: 1.6602 - acc: 0.4698 - val_loss: 1.3901 - val_acc: 0.6315\n","Epoch 2/100\n","35000/35000 [==============================] - 35s 1ms/step - loss: 1.4003 - acc: 0.6015 - val_loss: 1.2061 - val_acc: 0.6525\n","Epoch 3/100\n","35000/35000 [==============================] - 35s 999us/step - loss: 1.2590 - acc: 0.6364 - val_loss: 1.0996 - val_acc: 0.6610\n","Epoch 4/100\n","35000/35000 [==============================] - 35s 999us/step - loss: 1.1679 - acc: 0.6548 - val_loss: 1.0163 - val_acc: 0.6918\n","Epoch 5/100\n","35000/35000 [==============================] - 35s 1000us/step - loss: 1.0893 - acc: 0.6851 - val_loss: 0.9432 - val_acc: 0.7470\n","Epoch 6/100\n","35000/35000 [==============================] - 35s 998us/step - loss: 1.0251 - acc: 0.7078 - val_loss: 0.8896 - val_acc: 0.7488\n","Epoch 7/100\n","35000/35000 [==============================] - 35s 1ms/step - loss: 0.9718 - acc: 0.7213 - val_loss: 0.8409 - val_acc: 0.7580\n","Epoch 8/100\n","35000/35000 [==============================] - 35s 1000us/step - loss: 0.9248 - acc: 0.7329 - val_loss: 0.8093 - val_acc: 0.7580\n","Epoch 9/100\n","35000/35000 [==============================] - 35s 999us/step - loss: 0.8893 - acc: 0.7405 - val_loss: 0.7805 - val_acc: 0.7627\n","Epoch 10/100\n","35000/35000 [==============================] - 35s 999us/step - loss: 0.8567 - acc: 0.7427 - val_loss: 0.7586 - val_acc: 0.7715\n","Epoch 11/100\n","35000/35000 [==============================] - 35s 998us/step - loss: 0.8345 - acc: 0.7510 - val_loss: 0.7244 - val_acc: 0.7845\n","Epoch 12/100\n","35000/35000 [==============================] - 35s 999us/step - loss: 0.8049 - acc: 0.7597 - val_loss: 0.7056 - val_acc: 0.7895\n","Epoch 13/100\n","35000/35000 [==============================] - 35s 999us/step - loss: 0.7820 - acc: 0.7655 - val_loss: 0.6887 - val_acc: 0.7922\n","Epoch 14/100\n","35000/35000 [==============================] - 35s 999us/step - loss: 0.7591 - acc: 0.7695 - val_loss: 0.6754 - val_acc: 0.7923\n","Epoch 15/100\n","35000/35000 [==============================] - 35s 1ms/step - loss: 0.7446 - acc: 0.7747 - val_loss: 0.6504 - val_acc: 0.8003\n","Epoch 16/100\n","35000/35000 [==============================] - 35s 999us/step - loss: 0.7255 - acc: 0.7786 - val_loss: 0.6425 - val_acc: 0.8013\n","Epoch 17/100\n","35000/35000 [==============================] - 35s 999us/step - loss: 0.7097 - acc: 0.7842 - val_loss: 0.6317 - val_acc: 0.8015\n","Epoch 18/100\n","35000/35000 [==============================] - 35s 997us/step - loss: 0.6975 - acc: 0.7857 - val_loss: 0.6289 - val_acc: 0.8050\n","Epoch 19/100\n","35000/35000 [==============================] - 35s 999us/step - loss: 0.6862 - acc: 0.7902 - val_loss: 0.6153 - val_acc: 0.8153\n","Epoch 20/100\n","35000/35000 [==============================] - 35s 1000us/step - loss: 0.6780 - acc: 0.7936 - val_loss: 0.6125 - val_acc: 0.8123\n","Epoch 21/100\n","35000/35000 [==============================] - 35s 999us/step - loss: 0.6604 - acc: 0.7997 - val_loss: 0.6003 - val_acc: 0.8150\n","Epoch 22/100\n","35000/35000 [==============================] - 35s 1000us/step - loss: 0.6504 - acc: 0.8021 - val_loss: 0.5817 - val_acc: 0.8220\n","Epoch 23/100\n","35000/35000 [==============================] - 35s 998us/step - loss: 0.6395 - acc: 0.8049 - val_loss: 0.5845 - val_acc: 0.8148\n","Epoch 24/100\n","35000/35000 [==============================] - 35s 1000us/step - loss: 0.6294 - acc: 0.8094 - val_loss: 0.5846 - val_acc: 0.8192\n","Epoch 25/100\n","35000/35000 [==============================] - 35s 998us/step - loss: 0.6237 - acc: 0.8095 - val_loss: 0.5744 - val_acc: 0.8212\n","Epoch 26/100\n","35000/35000 [==============================] - 35s 999us/step - loss: 0.6176 - acc: 0.8117 - val_loss: 0.5713 - val_acc: 0.8190\n","Epoch 27/100\n","35000/35000 [==============================] - 35s 997us/step - loss: 0.6057 - acc: 0.8171 - val_loss: 0.5599 - val_acc: 0.8270\n","Epoch 28/100\n","35000/35000 [==============================] - 35s 998us/step - loss: 0.6008 - acc: 0.8163 - val_loss: 0.5602 - val_acc: 0.8233\n","Epoch 29/100\n","35000/35000 [==============================] - 35s 998us/step - loss: 0.5976 - acc: 0.8186 - val_loss: 0.5536 - val_acc: 0.8238\n","Epoch 30/100\n","35000/35000 [==============================] - 35s 998us/step - loss: 0.5869 - acc: 0.8194 - val_loss: 0.5409 - val_acc: 0.8272\n","Epoch 31/100\n","35000/35000 [==============================] - 35s 1000us/step - loss: 0.5807 - acc: 0.8218 - val_loss: 0.5401 - val_acc: 0.8302\n","Epoch 32/100\n","35000/35000 [==============================] - 35s 998us/step - loss: 0.5697 - acc: 0.8243 - val_loss: 0.5411 - val_acc: 0.8278\n","Epoch 33/100\n","35000/35000 [==============================] - 35s 998us/step - loss: 0.5623 - acc: 0.8285 - val_loss: 0.5432 - val_acc: 0.8285\n","Epoch 34/100\n","35000/35000 [==============================] - 35s 999us/step - loss: 0.5636 - acc: 0.8267 - val_loss: 0.5433 - val_acc: 0.8293\n","Epoch 35/100\n","35000/35000 [==============================] - 35s 999us/step - loss: 0.5574 - acc: 0.8277 - val_loss: 0.5301 - val_acc: 0.8312\n","Epoch 36/100\n","35000/35000 [==============================] - 35s 1000us/step - loss: 0.5450 - acc: 0.8319 - val_loss: 0.5319 - val_acc: 0.8285\n","Epoch 37/100\n","35000/35000 [==============================] - 35s 1ms/step - loss: 0.5368 - acc: 0.8350 - val_loss: 0.5260 - val_acc: 0.8293\n","Epoch 38/100\n","35000/35000 [==============================] - 35s 998us/step - loss: 0.5333 - acc: 0.8365 - val_loss: 0.5192 - val_acc: 0.8338\n","Epoch 39/100\n","35000/35000 [==============================] - 35s 998us/step - loss: 0.5332 - acc: 0.8359 - val_loss: 0.5207 - val_acc: 0.8327\n","Epoch 40/100\n","35000/35000 [==============================] - 35s 997us/step - loss: 0.5192 - acc: 0.8397 - val_loss: 0.5181 - val_acc: 0.8350\n","Epoch 41/100\n","35000/35000 [==============================] - 35s 999us/step - loss: 0.5219 - acc: 0.8371 - val_loss: 0.5152 - val_acc: 0.8362\n","Epoch 42/100\n","35000/35000 [==============================] - 35s 999us/step - loss: 0.5120 - acc: 0.8406 - val_loss: 0.5220 - val_acc: 0.8325\n","Epoch 43/100\n","35000/35000 [==============================] - 35s 997us/step - loss: 0.5105 - acc: 0.8417 - val_loss: 0.5189 - val_acc: 0.8293\n","Epoch 44/100\n","35000/35000 [==============================] - 35s 998us/step - loss: 0.5065 - acc: 0.8435 - val_loss: 0.5062 - val_acc: 0.8345\n","Epoch 45/100\n","35000/35000 [==============================] - 35s 996us/step - loss: 0.4964 - acc: 0.8456 - val_loss: 0.5097 - val_acc: 0.8345\n","Epoch 46/100\n","35000/35000 [==============================] - 35s 997us/step - loss: 0.4898 - acc: 0.8495 - val_loss: 0.5143 - val_acc: 0.8350\n","Epoch 47/100\n","35000/35000 [==============================] - 35s 997us/step - loss: 0.4877 - acc: 0.8486 - val_loss: 0.5079 - val_acc: 0.8375\n","Epoch 48/100\n","35000/35000 [==============================] - 35s 997us/step - loss: 0.4848 - acc: 0.8487 - val_loss: 0.5007 - val_acc: 0.8350\n","Epoch 49/100\n","35000/35000 [==============================] - 35s 997us/step - loss: 0.4789 - acc: 0.8498 - val_loss: 0.5026 - val_acc: 0.8405\n","Epoch 50/100\n","35000/35000 [==============================] - 35s 996us/step - loss: 0.4712 - acc: 0.8529 - val_loss: 0.5030 - val_acc: 0.8397\n","Epoch 51/100\n","35000/35000 [==============================] - 35s 995us/step - loss: 0.4658 - acc: 0.8540 - val_loss: 0.5014 - val_acc: 0.8407\n","Epoch 52/100\n","35000/35000 [==============================] - 35s 997us/step - loss: 0.4613 - acc: 0.8568 - val_loss: 0.5009 - val_acc: 0.8365\n","Epoch 53/100\n","35000/35000 [==============================] - 35s 998us/step - loss: 0.4619 - acc: 0.8556 - val_loss: 0.5011 - val_acc: 0.8390\n","Epoch 54/100\n","35000/35000 [==============================] - 35s 998us/step - loss: 0.4503 - acc: 0.8584 - val_loss: 0.5051 - val_acc: 0.8350\n","Epoch 55/100\n","35000/35000 [==============================] - 35s 1000us/step - loss: 0.4495 - acc: 0.8599 - val_loss: 0.4905 - val_acc: 0.8420\n","Epoch 56/100\n","35000/35000 [==============================] - 35s 996us/step - loss: 0.4441 - acc: 0.8618 - val_loss: 0.4989 - val_acc: 0.8377\n","Epoch 57/100\n","35000/35000 [==============================] - 35s 996us/step - loss: 0.4367 - acc: 0.8624 - val_loss: 0.4891 - val_acc: 0.8452\n","Epoch 58/100\n","35000/35000 [==============================] - 35s 999us/step - loss: 0.4394 - acc: 0.8615 - val_loss: 0.4873 - val_acc: 0.8480\n","Epoch 59/100\n","35000/35000 [==============================] - 35s 997us/step - loss: 0.4363 - acc: 0.8625 - val_loss: 0.4950 - val_acc: 0.8412\n","Epoch 60/100\n","35000/35000 [==============================] - 35s 997us/step - loss: 0.4312 - acc: 0.8639 - val_loss: 0.4827 - val_acc: 0.8425\n","Epoch 61/100\n","35000/35000 [==============================] - 35s 999us/step - loss: 0.4267 - acc: 0.8671 - val_loss: 0.4927 - val_acc: 0.8425\n","Epoch 62/100\n","35000/35000 [==============================] - 35s 998us/step - loss: 0.4195 - acc: 0.8681 - val_loss: 0.4912 - val_acc: 0.8440\n","Epoch 63/100\n","35000/35000 [==============================] - 35s 999us/step - loss: 0.4181 - acc: 0.8694 - val_loss: 0.4903 - val_acc: 0.8420\n","Epoch 64/100\n","35000/35000 [==============================] - 35s 997us/step - loss: 0.4112 - acc: 0.8718 - val_loss: 0.4811 - val_acc: 0.8483\n","Epoch 65/100\n","35000/35000 [==============================] - 35s 998us/step - loss: 0.4071 - acc: 0.8727 - val_loss: 0.4910 - val_acc: 0.8475\n","Epoch 66/100\n","35000/35000 [==============================] - 35s 995us/step - loss: 0.4016 - acc: 0.8719 - val_loss: 0.4948 - val_acc: 0.8443\n","Epoch 67/100\n","35000/35000 [==============================] - 35s 997us/step - loss: 0.3972 - acc: 0.8777 - val_loss: 0.4848 - val_acc: 0.8492\n","Epoch 68/100\n","35000/35000 [==============================] - 35s 997us/step - loss: 0.3891 - acc: 0.8766 - val_loss: 0.4870 - val_acc: 0.8478\n","Epoch 69/100\n","35000/35000 [==============================] - 35s 995us/step - loss: 0.3880 - acc: 0.8787 - val_loss: 0.4978 - val_acc: 0.8425\n","Epoch 70/100\n","35000/35000 [==============================] - 35s 997us/step - loss: 0.3868 - acc: 0.8784 - val_loss: 0.4853 - val_acc: 0.8458\n","Epoch 71/100\n","35000/35000 [==============================] - 35s 999us/step - loss: 0.3798 - acc: 0.8793 - val_loss: 0.4875 - val_acc: 0.8470\n","Epoch 72/100\n","35000/35000 [==============================] - 35s 998us/step - loss: 0.3799 - acc: 0.8795 - val_loss: 0.4827 - val_acc: 0.8493\n","Epoch 73/100\n","35000/35000 [==============================] - 35s 997us/step - loss: 0.3707 - acc: 0.8820 - val_loss: 0.4897 - val_acc: 0.8512\n","Epoch 74/100\n","35000/35000 [==============================] - 35s 996us/step - loss: 0.3694 - acc: 0.8842 - val_loss: 0.4819 - val_acc: 0.8480\n","Epoch 75/100\n","35000/35000 [==============================] - 35s 998us/step - loss: 0.3588 - acc: 0.8867 - val_loss: 0.4886 - val_acc: 0.8488\n","Epoch 76/100\n","35000/35000 [==============================] - 35s 995us/step - loss: 0.3573 - acc: 0.8884 - val_loss: 0.4894 - val_acc: 0.8513\n","Epoch 77/100\n","35000/35000 [==============================] - 35s 996us/step - loss: 0.3589 - acc: 0.8866 - val_loss: 0.4894 - val_acc: 0.8483\n","Epoch 78/100\n","35000/35000 [==============================] - 35s 996us/step - loss: 0.3545 - acc: 0.8882 - val_loss: 0.4928 - val_acc: 0.8497\n","Epoch 79/100\n","35000/35000 [==============================] - 35s 1ms/step - loss: 0.3516 - acc: 0.8888 - val_loss: 0.4884 - val_acc: 0.8490\n","Epoch 80/100\n","35000/35000 [==============================] - 35s 999us/step - loss: 0.3468 - acc: 0.8904 - val_loss: 0.4848 - val_acc: 0.8493\n","Epoch 81/100\n","35000/35000 [==============================] - 35s 997us/step - loss: 0.3447 - acc: 0.8911 - val_loss: 0.4870 - val_acc: 0.8522\n","Epoch 82/100\n","35000/35000 [==============================] - 35s 995us/step - loss: 0.3415 - acc: 0.8932 - val_loss: 0.4928 - val_acc: 0.8495\n","Epoch 83/100\n","35000/35000 [==============================] - 35s 998us/step - loss: 0.3379 - acc: 0.8932 - val_loss: 0.4888 - val_acc: 0.8530\n","Epoch 84/100\n","35000/35000 [==============================] - 35s 997us/step - loss: 0.3333 - acc: 0.8937 - val_loss: 0.4842 - val_acc: 0.8528\n","Epoch 85/100\n","35000/35000 [==============================] - 35s 996us/step - loss: 0.3307 - acc: 0.8962 - val_loss: 0.4880 - val_acc: 0.8512\n","Epoch 86/100\n","35000/35000 [==============================] - 35s 998us/step - loss: 0.3265 - acc: 0.8961 - val_loss: 0.5060 - val_acc: 0.8455\n","Epoch 87/100\n","35000/35000 [==============================] - 35s 998us/step - loss: 0.3230 - acc: 0.8971 - val_loss: 0.4928 - val_acc: 0.8510\n","Epoch 88/100\n","35000/35000 [==============================] - 35s 998us/step - loss: 0.3220 - acc: 0.8960 - val_loss: 0.4855 - val_acc: 0.8540\n","Epoch 89/100\n","35000/35000 [==============================] - 35s 995us/step - loss: 0.3129 - acc: 0.9016 - val_loss: 0.4860 - val_acc: 0.8550\n","Epoch 90/100\n","35000/35000 [==============================] - 35s 999us/step - loss: 0.3125 - acc: 0.9016 - val_loss: 0.4973 - val_acc: 0.8475\n","Epoch 91/100\n","35000/35000 [==============================] - 35s 996us/step - loss: 0.3054 - acc: 0.9033 - val_loss: 0.4995 - val_acc: 0.8520\n","Epoch 92/100\n","35000/35000 [==============================] - 35s 998us/step - loss: 0.3068 - acc: 0.9031 - val_loss: 0.4947 - val_acc: 0.8523\n","Epoch 93/100\n","35000/35000 [==============================] - 35s 997us/step - loss: 0.3054 - acc: 0.9037 - val_loss: 0.4997 - val_acc: 0.8523\n","Epoch 94/100\n","35000/35000 [==============================] - 35s 998us/step - loss: 0.3012 - acc: 0.9055 - val_loss: 0.4907 - val_acc: 0.8535\n","Epoch 95/100\n","35000/35000 [==============================] - 35s 996us/step - loss: 0.2945 - acc: 0.9070 - val_loss: 0.5021 - val_acc: 0.8477\n","Epoch 96/100\n","35000/35000 [==============================] - 35s 998us/step - loss: 0.2908 - acc: 0.9073 - val_loss: 0.5120 - val_acc: 0.8510\n","Epoch 97/100\n","35000/35000 [==============================] - 35s 998us/step - loss: 0.2912 - acc: 0.9066 - val_loss: 0.4960 - val_acc: 0.8545\n","Epoch 98/100\n","35000/35000 [==============================] - 35s 998us/step - loss: 0.2835 - acc: 0.9113 - val_loss: 0.5055 - val_acc: 0.8495\n","Epoch 99/100\n","35000/35000 [==============================] - 35s 997us/step - loss: 0.2835 - acc: 0.9083 - val_loss: 0.5128 - val_acc: 0.8515\n","Epoch 100/100\n","35000/35000 [==============================] - 35s 996us/step - loss: 0.2796 - acc: 0.9120 - val_loss: 0.4996 - val_acc: 0.8570\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BeaGmZ4wWq3w","colab_type":"code","colab":{}},"source":["predicts = model.predict(X_test)\n","import numpy as np\n","def decode(le, one_hot):\n","    dec = np.argmax(one_hot, axis=1)\n","    return le.inverse_transform(dec)\n","y_test = decode(le, y_test)\n","y_preds = decode(le, predicts)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MfRZa1gYWvf8","colab_type":"code","outputId":"e39b0158-454e-4b9e-e403-dda8d5397f55","executionInfo":{"status":"ok","timestamp":1560250452917,"user_tz":-360,"elapsed":3498169,"user":{"displayName":"Mahmudul Hasan","photoUrl":"","userId":"10838423032874605851"}},"colab":{"base_uri":"https://localhost:8080/","height":615}},"source":["from sklearn import metrics\n","\n","print(metrics.accuracy_score(y_test, y_preds))\n","\n","print(metrics.confusion_matrix(y_test, y_preds))\n","\n","print(metrics.classification_report(y_test, y_preds))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0.842\n","[[  4   1   0   0   0   1   0   0   0   3   1   0]\n"," [  0 251   0  15   4   1   5   3   0  24   0   1]\n"," [  0   0   0   0   0   1   1   0   0   2   0   0]\n"," [  0  12   0  86   0   1   1   0   0  10   0   2]\n"," [  0   7   0   1  16   1   0   0   0   1   0   0]\n"," [  1   0   0   0   0  59   1   2   0   3   1   2]\n"," [  0   2   0   0   0   0  43   0   0   3   0   0]\n"," [  1   1   0   1   1   0   0  20   0   2   0   2]\n"," [  0   0   0   0   0   0   1   0   0   1   0   0]\n"," [  2  12   0   3   1   2   3   2   0 252   1   1]\n"," [  1   1   0   0   0   0   1   0   0   1  69   0]\n"," [  0   0   0   1   0   0   0   2   0   0   0  42]]\n","                    precision    recall  f1-score   support\n","\n","art-and-literature       0.44      0.40      0.42        10\n","        bangladesh       0.87      0.83      0.85       304\n","       durporobash       0.00      0.00      0.00         4\n","           economy       0.80      0.77      0.79       112\n","         education       0.73      0.62      0.67        26\n","     entertainment       0.89      0.86      0.87        69\n","     international       0.77      0.90      0.83        48\n","        life-style       0.69      0.71      0.70        28\n","      northamerica       0.00      0.00      0.00         2\n","           opinion       0.83      0.90      0.87       279\n","            sports       0.96      0.95      0.95        73\n","        technology       0.84      0.93      0.88        45\n","\n","          accuracy                           0.84      1000\n","         macro avg       0.65      0.65      0.65      1000\n","      weighted avg       0.84      0.84      0.84      1000\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n","  'precision', 'predicted', average, warn_for)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ahSRhD2YWyE8","colab_type":"code","colab":{}},"source":["accuracy, val_accuracy = np.array(history.history[\"acc\"]), np.array(history.history[\"val_acc\"])\n","accuracy, val_accuracy = accuracy.reshape(100,1), val_accuracy.reshape(100,1)\n","accuracies = np.concatenate((accuracy,val_accuracy),axis=1)\n","np.savetxt('/content/gdrive/My Drive/Projects/Bengali Text Classification/temp.csv',accuracies,delimiter=\",\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rVU2P_fwZH0W","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}