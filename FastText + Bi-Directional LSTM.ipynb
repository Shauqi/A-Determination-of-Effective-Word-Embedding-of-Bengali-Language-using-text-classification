{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FastText + Bi-Directional LSTM.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"FZvP_g-SV47j","colab_type":"code","outputId":"eeaba686-39b5-4832-a7d6-db8c5d4d5981","executionInfo":{"status":"ok","timestamp":1560518947692,"user_tz":-360,"elapsed":19372,"user":{"displayName":"Mahmudul Hasan","photoUrl":"","userId":"10838423032874605851"}},"colab":{"base_uri":"https://localhost:8080/","height":88}},"source":["from google.colab import drive\n","import numpy as np\n","import pandas as pd\n","drive.mount('/content/gdrive')\n","bengali_news_after_preprocessing = pd.read_pickle('/content/gdrive/My Drive/Projects/Bengali Text Classification/Bengali_Text_after_preprocessing.pkl')\n","from sklearn.externals import joblib\n","filename = '/content/gdrive/My Drive/Projects/Bengali Text Classification/fastText_Bangla_content_full.sav'\n","loaded_model = joblib.load(filename)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n","  warnings.warn(msg, category=DeprecationWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Bh152mlTWClV","colab_type":"code","outputId":"737ac92e-aeea-4be6-e1a3-57e9f5510e7e","executionInfo":{"status":"ok","timestamp":1560518955463,"user_tz":-360,"elapsed":3266,"user":{"displayName":"Mahmudul Hasan","photoUrl":"","userId":"10838423032874605851"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import keras.backend as K\n","import numpy as np\n","number_of_sample, max_number_of_words, word_vector_size = 40000, 100, 32\n","temp = bengali_news_after_preprocessing.loc[:number_of_sample-1,:max_number_of_words-1]"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"BL1dPKt5WNAp","colab_type":"code","colab":{}},"source":["temp = temp.replace(['ঘস', 'ফগ', 'ঝবঃ', 'ঋন', 'ঊঘ', '\\u09e4', 'ওৎ', 'গথ', 'খঢ', 'ঝ’', 'ং', 'ঔ', 'ডড', 'গঘ','ঐব','ওঃ’ং','ুী','খষ','ি'], None)\n","X = np.zeros((number_of_sample, max_number_of_words, word_vector_size), dtype=K.floatx())\n","for i in temp.index:\n","  X[i,:,:] = loaded_model.wv[temp.loc[i,:]]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kx4gwqnUWO8R","colab_type":"code","colab":{}},"source":["bengali_news = pd.read_pickle('/content/gdrive/My Drive/Projects/Bengali Text Classification/40k_bangla_newspaper_article.p')\n","bengali_news_dataframe = pd.DataFrame(bengali_news)\n","y = bengali_news_dataframe['category']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pDj7CROuWRrp","colab_type":"code","colab":{}},"source":["from sklearn import preprocessing\n","import keras\n","import numpy as np\n","le = preprocessing.LabelEncoder()\n","le.fit(y)\n","enc = le.transform(y)\n","y = keras.utils.to_categorical(enc)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ltHADvLlWVsg","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","X_train, X_val, y_train, y_val = train_test_split(X, y, shuffle = True, test_size=0.125)\n","X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, shuffle = True, test_size=0.20)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"g2Z737RiWYM4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":309},"outputId":"7a76094e-65be-4bc8-b7f9-366c7da75e68","executionInfo":{"status":"ok","timestamp":1560519025249,"user_tz":-360,"elapsed":5386,"user":{"displayName":"Mahmudul Hasan","photoUrl":"","userId":"10838423032874605851"}}},"source":["from keras.models import Sequential\n","from keras.layers import Conv1D, Dropout, Dense, Flatten, LSTM, MaxPooling1D, Bidirectional\n","from keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping, TensorBoard\n","\n","\n","model = Sequential()\n","\n","model.add(Bidirectional(LSTM(512, dropout=0.2, recurrent_dropout=0.3), input_shape=(max_number_of_words, word_vector_size)))\n","model.add(Dense(256, activation='sigmoid'))\n","model.add(Dropout(0.2))\n","model.add(Dense(256, activation='sigmoid'))\n","model.add(Dropout(0.25))\n","model.add(Dense(256, activation='sigmoid'))\n","model.add(Dropout(0.25))\n","\n","model.add(Dense(13, activation='softmax'))\n","\n","model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001, decay=1e-6), metrics=['accuracy'])"],"execution_count":7,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0614 13:31:34.678698 140338445772672 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0614 13:31:34.692787 140338445772672 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0614 13:31:34.695993 140338445772672 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","W0614 13:31:36.058312 140338445772672 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","W0614 13:31:36.072264 140338445772672 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","W0614 13:31:37.064224 140338445772672 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","W0614 13:31:37.079809 140338445772672 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"9JD8UfRZWdcI","colab_type":"code","outputId":"27d2047d-0f31-4b43-fc5e-1812e5169262","executionInfo":{"status":"ok","timestamp":1560519025251,"user_tz":-360,"elapsed":5368,"user":{"displayName":"Mahmudul Hasan","photoUrl":"","userId":"10838423032874605851"}},"colab":{"base_uri":"https://localhost:8080/","height":408}},"source":["model.summary()"],"execution_count":8,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","bidirectional_1 (Bidirection (None, 1024)              2232320   \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 256)               262400    \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 256)               65792     \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 256)               65792     \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 256)               0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 13)                3341      \n","=================================================================\n","Total params: 2,629,645\n","Trainable params: 2,629,645\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bkrt1heEWoWg","colab_type":"code","outputId":"2bc4cf8a-c8c5-4231-e876-7c1902862845","executionInfo":{"status":"ok","timestamp":1560526111283,"user_tz":-360,"elapsed":3264,"user":{"displayName":"Mahmudul Hasan","photoUrl":"","userId":"10838423032874605851"}},"colab":{"base_uri":"https://localhost:8080/","height":3505}},"source":["history = model.fit(X_train, y_train, batch_size= 500, shuffle=True, epochs= 100, validation_data=(X_val, y_val))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["W0614 13:31:37.277363 140338445772672 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 35000 samples, validate on 4000 samples\n","Epoch 1/100\n","35000/35000 [==============================] - 69s 2ms/step - loss: 2.3800 - acc: 0.2004 - val_loss: 1.8559 - val_acc: 0.4445\n","Epoch 2/100\n","35000/35000 [==============================] - 66s 2ms/step - loss: 1.7949 - acc: 0.4079 - val_loss: 1.5645 - val_acc: 0.4805\n","Epoch 3/100\n","35000/35000 [==============================] - 67s 2ms/step - loss: 1.5341 - acc: 0.5404 - val_loss: 1.3555 - val_acc: 0.6358\n","Epoch 4/100\n","35000/35000 [==============================] - 67s 2ms/step - loss: 1.3522 - acc: 0.6162 - val_loss: 1.1977 - val_acc: 0.6650\n","Epoch 5/100\n","35000/35000 [==============================] - 67s 2ms/step - loss: 1.2331 - acc: 0.6437 - val_loss: 1.1088 - val_acc: 0.6640\n","Epoch 6/100\n","35000/35000 [==============================] - 67s 2ms/step - loss: 1.1473 - acc: 0.6582 - val_loss: 1.0435 - val_acc: 0.6740\n","Epoch 7/100\n","35000/35000 [==============================] - 67s 2ms/step - loss: 1.0847 - acc: 0.6699 - val_loss: 0.9874 - val_acc: 0.7002\n","Epoch 8/100\n","35000/35000 [==============================] - 67s 2ms/step - loss: 1.0373 - acc: 0.6861 - val_loss: 0.9421 - val_acc: 0.7008\n","Epoch 9/100\n","35000/35000 [==============================] - 67s 2ms/step - loss: 0.9986 - acc: 0.6936 - val_loss: 0.9113 - val_acc: 0.7045\n","Epoch 10/100\n","35000/35000 [==============================] - 67s 2ms/step - loss: 0.9578 - acc: 0.7081 - val_loss: 0.8614 - val_acc: 0.7180\n","Epoch 11/100\n","35000/35000 [==============================] - 67s 2ms/step - loss: 0.9148 - acc: 0.7280 - val_loss: 0.8269 - val_acc: 0.7648\n","Epoch 12/100\n","35000/35000 [==============================] - 67s 2ms/step - loss: 0.8767 - acc: 0.7478 - val_loss: 0.7827 - val_acc: 0.7753\n","Epoch 13/100\n","35000/35000 [==============================] - 67s 2ms/step - loss: 0.8396 - acc: 0.7614 - val_loss: 0.7668 - val_acc: 0.7785\n","Epoch 14/100\n","35000/35000 [==============================] - 67s 2ms/step - loss: 0.8174 - acc: 0.7653 - val_loss: 0.7389 - val_acc: 0.7837\n","Epoch 15/100\n","35000/35000 [==============================] - 67s 2ms/step - loss: 0.7951 - acc: 0.7701 - val_loss: 0.7211 - val_acc: 0.7905\n","Epoch 16/100\n","35000/35000 [==============================] - 67s 2ms/step - loss: 0.7709 - acc: 0.7753 - val_loss: 0.7026 - val_acc: 0.7953\n","Epoch 17/100\n","35000/35000 [==============================] - 67s 2ms/step - loss: 0.7553 - acc: 0.7810 - val_loss: 0.6904 - val_acc: 0.7972\n","Epoch 18/100\n","35000/35000 [==============================] - 67s 2ms/step - loss: 0.7382 - acc: 0.7840 - val_loss: 0.6914 - val_acc: 0.7975\n","Epoch 19/100\n","35000/35000 [==============================] - 67s 2ms/step - loss: 0.7229 - acc: 0.7881 - val_loss: 0.6600 - val_acc: 0.8080\n","Epoch 20/100\n","35000/35000 [==============================] - 67s 2ms/step - loss: 0.7069 - acc: 0.7927 - val_loss: 0.6490 - val_acc: 0.8098\n","Epoch 21/100\n","35000/35000 [==============================] - 67s 2ms/step - loss: 0.6981 - acc: 0.7956 - val_loss: 0.6282 - val_acc: 0.8160\n","Epoch 22/100\n","35000/35000 [==============================] - 67s 2ms/step - loss: 0.6790 - acc: 0.7994 - val_loss: 0.6229 - val_acc: 0.8213\n","Epoch 23/100\n","35000/35000 [==============================] - 67s 2ms/step - loss: 0.6675 - acc: 0.8041 - val_loss: 0.6216 - val_acc: 0.8210\n","Epoch 24/100\n","35000/35000 [==============================] - 67s 2ms/step - loss: 0.6615 - acc: 0.8058 - val_loss: 0.6027 - val_acc: 0.8250\n","Epoch 25/100\n","35000/35000 [==============================] - 67s 2ms/step - loss: 0.6435 - acc: 0.8099 - val_loss: 0.5892 - val_acc: 0.8313\n","Epoch 26/100\n","35000/35000 [==============================] - 67s 2ms/step - loss: 0.6339 - acc: 0.8138 - val_loss: 0.5791 - val_acc: 0.8315\n","Epoch 27/100\n","35000/35000 [==============================] - 67s 2ms/step - loss: 0.6162 - acc: 0.8218 - val_loss: 0.5725 - val_acc: 0.8368\n","Epoch 28/100\n","35000/35000 [==============================] - 67s 2ms/step - loss: 0.6104 - acc: 0.8206 - val_loss: 0.5717 - val_acc: 0.8355\n","Epoch 29/100\n","35000/35000 [==============================] - 67s 2ms/step - loss: 0.6003 - acc: 0.8229 - val_loss: 0.5638 - val_acc: 0.8345\n","Epoch 30/100\n","35000/35000 [==============================] - 67s 2ms/step - loss: 0.5918 - acc: 0.8277 - val_loss: 0.5378 - val_acc: 0.8418\n","Epoch 31/100\n","35000/35000 [==============================] - 67s 2ms/step - loss: 0.5824 - acc: 0.8301 - val_loss: 0.5401 - val_acc: 0.8413\n","Epoch 32/100\n","35000/35000 [==============================] - 67s 2ms/step - loss: 0.5747 - acc: 0.8305 - val_loss: 0.5343 - val_acc: 0.8417\n","Epoch 33/100\n","35000/35000 [==============================] - 67s 2ms/step - loss: 0.5628 - acc: 0.8316 - val_loss: 0.5334 - val_acc: 0.8368\n","Epoch 34/100\n","35000/35000 [==============================] - 67s 2ms/step - loss: 0.5594 - acc: 0.8332 - val_loss: 0.5257 - val_acc: 0.8400\n","Epoch 35/100\n","35000/35000 [==============================] - 67s 2ms/step - loss: 0.5489 - acc: 0.8350 - val_loss: 0.5172 - val_acc: 0.8432\n","Epoch 36/100\n","35000/35000 [==============================] - 67s 2ms/step - loss: 0.5429 - acc: 0.8369 - val_loss: 0.5173 - val_acc: 0.8485\n","Epoch 37/100\n","35000/35000 [==============================] - 67s 2ms/step - loss: 0.5334 - acc: 0.8400 - val_loss: 0.5086 - val_acc: 0.8448\n","Epoch 38/100\n","35000/35000 [==============================] - 67s 2ms/step - loss: 0.5264 - acc: 0.8415 - val_loss: 0.5031 - val_acc: 0.8467\n","Epoch 39/100\n","35000/35000 [==============================] - 67s 2ms/step - loss: 0.5245 - acc: 0.8423 - val_loss: 0.5031 - val_acc: 0.8505\n","Epoch 40/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.5206 - acc: 0.8439 - val_loss: 0.4978 - val_acc: 0.8473\n","Epoch 41/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.5120 - acc: 0.8450 - val_loss: 0.4927 - val_acc: 0.8498\n","Epoch 42/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.5101 - acc: 0.8467 - val_loss: 0.4928 - val_acc: 0.8525\n","Epoch 43/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.5003 - acc: 0.8485 - val_loss: 0.4895 - val_acc: 0.8530\n","Epoch 44/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.4874 - acc: 0.8530 - val_loss: 0.4883 - val_acc: 0.8520\n","Epoch 45/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.4839 - acc: 0.8532 - val_loss: 0.4849 - val_acc: 0.8540\n","Epoch 46/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.4797 - acc: 0.8521 - val_loss: 0.4768 - val_acc: 0.8555\n","Epoch 47/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.4728 - acc: 0.8575 - val_loss: 0.4722 - val_acc: 0.8570\n","Epoch 48/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.4665 - acc: 0.8576 - val_loss: 0.4722 - val_acc: 0.8550\n","Epoch 49/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.4671 - acc: 0.8591 - val_loss: 0.4757 - val_acc: 0.8532\n","Epoch 50/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.4563 - acc: 0.8619 - val_loss: 0.4656 - val_acc: 0.8570\n","Epoch 51/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.4524 - acc: 0.8601 - val_loss: 0.4636 - val_acc: 0.8577\n","Epoch 52/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.4493 - acc: 0.8639 - val_loss: 0.4665 - val_acc: 0.8588\n","Epoch 53/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.4469 - acc: 0.8634 - val_loss: 0.4615 - val_acc: 0.8615\n","Epoch 54/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.4361 - acc: 0.8663 - val_loss: 0.4574 - val_acc: 0.8613\n","Epoch 55/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.4358 - acc: 0.8667 - val_loss: 0.4587 - val_acc: 0.8615\n","Epoch 56/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.4273 - acc: 0.8697 - val_loss: 0.4552 - val_acc: 0.8597\n","Epoch 57/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.4229 - acc: 0.8685 - val_loss: 0.4537 - val_acc: 0.8647\n","Epoch 58/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.4228 - acc: 0.8709 - val_loss: 0.4542 - val_acc: 0.8620\n","Epoch 59/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.4208 - acc: 0.8695 - val_loss: 0.4521 - val_acc: 0.8643\n","Epoch 60/100\n","35000/35000 [==============================] - 69s 2ms/step - loss: 0.4139 - acc: 0.8717 - val_loss: 0.4453 - val_acc: 0.8613\n","Epoch 61/100\n","35000/35000 [==============================] - 69s 2ms/step - loss: 0.4080 - acc: 0.8746 - val_loss: 0.4451 - val_acc: 0.8625\n","Epoch 62/100\n","35000/35000 [==============================] - 69s 2ms/step - loss: 0.3995 - acc: 0.8765 - val_loss: 0.4441 - val_acc: 0.8660\n","Epoch 63/100\n","35000/35000 [==============================] - 69s 2ms/step - loss: 0.4036 - acc: 0.8771 - val_loss: 0.4375 - val_acc: 0.8670\n","Epoch 64/100\n","35000/35000 [==============================] - 69s 2ms/step - loss: 0.3953 - acc: 0.8791 - val_loss: 0.4468 - val_acc: 0.8615\n","Epoch 65/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.3924 - acc: 0.8805 - val_loss: 0.4413 - val_acc: 0.8638\n","Epoch 66/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.3874 - acc: 0.8801 - val_loss: 0.4357 - val_acc: 0.8657\n","Epoch 67/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.3811 - acc: 0.8820 - val_loss: 0.4377 - val_acc: 0.8657\n","Epoch 68/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.3790 - acc: 0.8832 - val_loss: 0.4421 - val_acc: 0.8665\n","Epoch 69/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.3769 - acc: 0.8830 - val_loss: 0.4388 - val_acc: 0.8692\n","Epoch 70/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.3693 - acc: 0.8857 - val_loss: 0.4302 - val_acc: 0.8680\n","Epoch 71/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.3660 - acc: 0.8869 - val_loss: 0.4289 - val_acc: 0.8710\n","Epoch 72/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.3630 - acc: 0.8882 - val_loss: 0.4441 - val_acc: 0.8692\n","Epoch 73/100\n","35000/35000 [==============================] - 69s 2ms/step - loss: 0.3600 - acc: 0.8902 - val_loss: 0.4402 - val_acc: 0.8690\n","Epoch 74/100\n","35000/35000 [==============================] - 69s 2ms/step - loss: 0.3548 - acc: 0.8903 - val_loss: 0.4308 - val_acc: 0.8740\n","Epoch 75/100\n","35000/35000 [==============================] - 69s 2ms/step - loss: 0.3505 - acc: 0.8912 - val_loss: 0.4283 - val_acc: 0.8727\n","Epoch 76/100\n","35000/35000 [==============================] - 69s 2ms/step - loss: 0.3454 - acc: 0.8931 - val_loss: 0.4389 - val_acc: 0.8700\n","Epoch 77/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.3472 - acc: 0.8940 - val_loss: 0.4240 - val_acc: 0.8727\n","Epoch 78/100\n","35000/35000 [==============================] - 69s 2ms/step - loss: 0.3424 - acc: 0.8927 - val_loss: 0.4311 - val_acc: 0.8730\n","Epoch 79/100\n","35000/35000 [==============================] - 69s 2ms/step - loss: 0.3346 - acc: 0.8951 - val_loss: 0.4265 - val_acc: 0.8727\n","Epoch 80/100\n","35000/35000 [==============================] - 69s 2ms/step - loss: 0.3322 - acc: 0.8981 - val_loss: 0.4320 - val_acc: 0.8740\n","Epoch 81/100\n","35000/35000 [==============================] - 69s 2ms/step - loss: 0.3303 - acc: 0.8980 - val_loss: 0.4247 - val_acc: 0.8737\n","Epoch 82/100\n","35000/35000 [==============================] - 69s 2ms/step - loss: 0.3236 - acc: 0.8983 - val_loss: 0.4228 - val_acc: 0.8753\n","Epoch 83/100\n","35000/35000 [==============================] - 69s 2ms/step - loss: 0.3234 - acc: 0.9015 - val_loss: 0.4235 - val_acc: 0.8733\n","Epoch 84/100\n","35000/35000 [==============================] - 69s 2ms/step - loss: 0.3151 - acc: 0.9025 - val_loss: 0.4295 - val_acc: 0.8750\n","Epoch 85/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.3151 - acc: 0.9013 - val_loss: 0.4199 - val_acc: 0.8778\n","Epoch 86/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.3134 - acc: 0.9027 - val_loss: 0.4255 - val_acc: 0.8747\n","Epoch 87/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.3093 - acc: 0.9029 - val_loss: 0.4248 - val_acc: 0.8788\n","Epoch 88/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.3076 - acc: 0.9023 - val_loss: 0.4181 - val_acc: 0.8748\n","Epoch 89/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.3029 - acc: 0.9065 - val_loss: 0.4173 - val_acc: 0.8760\n","Epoch 90/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.2976 - acc: 0.9067 - val_loss: 0.4280 - val_acc: 0.8760\n","Epoch 91/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.2986 - acc: 0.9064 - val_loss: 0.4239 - val_acc: 0.8778\n","Epoch 92/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.2952 - acc: 0.9064 - val_loss: 0.4222 - val_acc: 0.8800\n","Epoch 93/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.2914 - acc: 0.9092 - val_loss: 0.4157 - val_acc: 0.8810\n","Epoch 94/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.2871 - acc: 0.9105 - val_loss: 0.4218 - val_acc: 0.8792\n","Epoch 95/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.2812 - acc: 0.9128 - val_loss: 0.4266 - val_acc: 0.8765\n","Epoch 96/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.2820 - acc: 0.9123 - val_loss: 0.4271 - val_acc: 0.8785\n","Epoch 97/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.2783 - acc: 0.9124 - val_loss: 0.4188 - val_acc: 0.8825\n","Epoch 98/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.2755 - acc: 0.9158 - val_loss: 0.4266 - val_acc: 0.8805\n","Epoch 99/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.2721 - acc: 0.9163 - val_loss: 0.4374 - val_acc: 0.8787\n","Epoch 100/100\n","35000/35000 [==============================] - 68s 2ms/step - loss: 0.2737 - acc: 0.9149 - val_loss: 0.4374 - val_acc: 0.8787\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BeaGmZ4wWq3w","colab_type":"code","colab":{}},"source":["predicts = model.predict(X_test)\n","import numpy as np\n","def decode(le, one_hot):\n","    dec = np.argmax(one_hot, axis=1)\n","    return le.inverse_transform(dec)\n","y_test = decode(le, y_test)\n","y_preds = decode(le, predicts)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MfRZa1gYWvf8","colab_type":"code","outputId":"750f6283-7b62-41b4-e6aa-e19675040335","executionInfo":{"status":"ok","timestamp":1560526111292,"user_tz":-360,"elapsed":39,"user":{"displayName":"Mahmudul Hasan","photoUrl":"","userId":"10838423032874605851"}},"colab":{"base_uri":"https://localhost:8080/","height":615}},"source":["from sklearn import metrics\n","\n","print(metrics.accuracy_score(y_test, y_preds))\n","\n","print(metrics.confusion_matrix(y_test, y_preds))\n","\n","print(metrics.classification_report(y_test, y_preds))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["0.855\n","[[  4   0   0   0   0   2   0   0   0   2   0   0]\n"," [  1 252   0   6   3   3   2   0   0  20   1   1]\n"," [  1   1   0   0   0   1   1   1   0   3   0   0]\n"," [  0   9   0 101   0   0   0   0   0   9   0   4]\n"," [  2   2   0   4  12   0   0   0   0   1   0   1]\n"," [  0   1   0   0   0  62   1   0   0   1   1   0]\n"," [  0   5   0   0   0   2  42   0   0   8   0   1]\n"," [  0   2   0   0   1   2   0  28   0   4   0   0]\n"," [  0   0   0   0   0   0   1   0   0   2   0   0]\n"," [  1  10   0   0   1   1   1   3   0 237   2   0]\n"," [  0   2   0   0   1   1   0   0   0   2  73   0]\n"," [  0   1   0   3   1   0   1   1   0   0   0  44]]\n","                    precision    recall  f1-score   support\n","\n","art-and-literature       0.44      0.50      0.47         8\n","        bangladesh       0.88      0.87      0.88       289\n","       durporobash       0.00      0.00      0.00         8\n","           economy       0.89      0.82      0.85       123\n","         education       0.63      0.55      0.59        22\n","     entertainment       0.84      0.94      0.89        66\n","     international       0.86      0.72      0.79        58\n","        life-style       0.85      0.76      0.80        37\n","      northamerica       0.00      0.00      0.00         3\n","           opinion       0.82      0.93      0.87       256\n","            sports       0.95      0.92      0.94        79\n","        technology       0.86      0.86      0.86        51\n","\n","          accuracy                           0.85      1000\n","         macro avg       0.67      0.66      0.66      1000\n","      weighted avg       0.85      0.85      0.85      1000\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n","  'precision', 'predicted', average, warn_for)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ahSRhD2YWyE8","colab_type":"code","colab":{}},"source":["accuracy, val_accuracy = np.array(history.history[\"acc\"]), np.array(history.history[\"val_acc\"])\n","accuracy, val_accuracy = accuracy.reshape(100,1), val_accuracy.reshape(100,1)\n","accuracies = np.concatenate((accuracy,val_accuracy),axis=1)\n","np.savetxt('/content/gdrive/My Drive/Projects/Bengali Text Classification/temp.csv',accuracies,delimiter=\",\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rVU2P_fwZH0W","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}